import asyncio
from sqlalchemy import text
from app.core.database import AsyncSessionLocal, engine, Base
import app.core.models.regulation_model 

# [1] ëª¨ë“  í¬ë¡¤ëŸ¬ ì„í¬íŠ¸
from app.crawler.crawling_regulation.usa_fda import USAFDACrawler
from app.crawler.crawling_regulation.california_law import CaliforniaLawCrawler
from app.crawler.crawling_regulation.sf_bos_selenium import SFBOSSeleniumCrawler # Selenium ë²„ì „ ì‚¬ìš©

from app.core.repositories.crawl_repository import CrawlRepository

async def init_seed_data(db):
    """êµ­ê°€ ë° ë°ì´í„° ì†ŒìŠ¤ ê¸°ì´ˆ ë°ì´í„° ìƒì„±"""
    print("âš™ï¸ ê¸°ì´ˆ ë°ì´í„°(Seed) ì ê²€ ì¤‘...")
    try:
        # 1. êµ­ê°€ ì½”ë“œ (US)
        if not (await db.execute(text("SELECT 1 FROM countries WHERE country_code = 'US'"))).scalar():
            await db.execute(text("INSERT INTO countries (country_code, country_name) VALUES ('US', 'United States')"))
        
        # 2. ë°ì´í„° ì†ŒìŠ¤ (ID 1: FDA, 2: CA, 3: SF)
        sources = [
            (1, 'US FDA', 'https://www.fda.gov', 'html'),
            (2, 'CA Legislature', 'https://leginfo.legislature.ca.gov', 'html'),
            (3, 'San Francisco BOS', 'https://sfbos.org', 'html')
        ]
        
        for s_id, s_name, s_url, s_type in sources:
            if not (await db.execute(text(f"SELECT 1 FROM data_sources WHERE source_id = {s_id}"))).scalar():
                print(f"   + ì†ŒìŠ¤ ì¶”ê°€: {s_name}")
                await db.execute(text(f"INSERT INTO data_sources (source_id, source_name, url, source_type) VALUES ({s_id}, '{s_name}', '{s_url}', '{s_type}')"))
        
        await db.commit()
        print("âœ… ê¸°ì´ˆ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ê¸°ì´ˆ ë°ì´í„° ìƒì„± ì¤‘ ê²½ê³ : {e}")
        await db.rollback()

async def run_single_crawler(crawler_cls, source_name):
    """ë‹¨ì¼ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ë° ì €ì¥ ë¡œì§"""
    print(f"\nğŸš€ [{source_name}] í¬ë¡¤ë§ ì‹œì‘...")
    
    crawler = crawler_cls() # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    try:
        # 1. ë°ì´í„° ìˆ˜ì§‘
        data_list = await crawler.run()
        print(f"ğŸ“¦ [{source_name}] ìˆ˜ì§‘ëœ ë°ì´í„°: {len(data_list)}ê±´")

        if not data_list:
            print(f"âš ï¸ [{source_name}] ë°ì´í„° ì—†ìŒ. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return

        # 2. DB ì €ì¥ ë° ì²˜ë¦¬
        async with AsyncSessionLocal() as db:
            service = CrawlRepository(db)
            
            success = 0
            skipped = 0
            errors = 0

            print(f"ğŸ’¾ [{source_name}] ì €ì¥ ë° ë¶„ì„ ì¤‘...")
            for data in data_list:
                try:
                    # CrawlRepositoryê°€ ì•Œì•„ì„œ urlë¡œ ì¤‘ë³µ ì²´í¬ ë° ë‹¤ìš´ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
                    result = await service.process_crawled_data(data, crawler)
                    if result == "skipped": skipped += 1
                    else: success += 1
                except Exception as e:
                    print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
                    errors += 1
                    await db.rollback()
            
            print(f"ğŸ“Š [{source_name}] ê²°ê³¼: ì„±ê³µ {success} / ìŠ¤í‚µ {skipped} / ì—ëŸ¬ {errors}")

    except Exception as e:
        print(f"âŒ [{source_name}] í¬ë¡¤ëŸ¬ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
    finally:
        await crawler.close()

async def main():
    # 1. í…Œì´ë¸” ìƒì„±
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    # 2. ê¸°ì´ˆ ë°ì´í„° ì´ˆê¸°í™”
    async with AsyncSessionLocal() as db:
        await init_seed_data(db)

    # [3] ì‹¤í–‰í•  í¬ë¡¤ëŸ¬ ëª©ë¡ ì •ì˜
    # (í´ë˜ìŠ¤ëª…, í‘œì‹œì´ë¦„) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    crawlers_to_run = [
        (USAFDACrawler, "US FDA"),
        (CaliforniaLawCrawler, "California Law"),
        (SFBOSSeleniumCrawler, "SF Board of Supervisors"),
    ]

    # 4. ìˆœì°¨ ì‹¤í–‰
    print("\n" + "="*50)
    print("ğŸŒ ê¸€ë¡œë²Œ ê·œì œ í†µí•© ìˆ˜ì§‘ ì‹œì‘")
    print("="*50)

    for crawler_cls, name in crawlers_to_run:
        await run_single_crawler(crawler_cls, name)
        # ë‹¤ìŒ ì‚¬ì´íŠ¸ ë„˜ì–´ê°€ê¸° ì „ ì ê¹ ëŒ€ê¸° (ì„ íƒì‚¬í•­)
        await asyncio.sleep(2) 

    print("\n" + "="*50)
    print("ğŸ‰ ëª¨ë“  í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ!")
    print("="*50)
    await engine.dispose()

if __name__ == "__main__":
    asyncio.run(main())