import hashlib
from typing import Optional, Dict, Union
from curl_cffi.requests import AsyncSession

class UniversalFetcher:
    """
    [ë²”ìš©ì„± í•µì‹¬]
    íŠ¹ì • ì‚¬ì´íŠ¸ ì „ìš© í¬ë¡¤ëŸ¬ë¥¼ ìƒì†ë°›ì•„ ë§Œë“œëŠ” ë¶€ëª¨ í´ëž˜ìŠ¤ê°€ ì•„ë‹ˆë¼,
    Discovery Agentê°€ URLì„ ë°œê²¬í•˜ë©´ ì¦‰ì‹œ ì¶œë™í•´ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” 'ë…ë¦½ ì‹¤í–‰í˜• ë„êµ¬'ìž…ë‹ˆë‹¤.
    """
    def __init__(self, headers: Optional[Dict[str, str]] = None):
        # ê¸°ë³¸ í—¤ë”: ë²”ìš©ì„±ì„ ìœ„í•´ ì¼ë°˜ì ì¸ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ìœ„ìž¥
        default_headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9",
        }
        
        if headers:
            default_headers.update(headers)

        # impersonate="chrome120": í´ë¼ìš°ë“œí”Œë ˆì–´ ë“± ë³´ì•ˆ ì†”ë£¨ì…˜ ìš°íšŒì— í•„ìˆ˜
        self.session = AsyncSession(
            impersonate="chrome120", 
            headers=default_headers,
            timeout=30,
            verify=False # SSL ì—ëŸ¬ ë¬´ì‹œ (ì˜¤ëž˜ëœ ì •ë¶€ ì‚¬ì´íŠ¸ í˜¸í™˜ì„±)
        )

    def generate_hash(self, content: Union[str, bytes]) -> str:
        """ë°ì´í„° ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ í•´ì‹œ ìƒì„±"""
        if isinstance(content, str):
            content = content.encode('utf-8')
        return hashlib.sha256(content).hexdigest()

    async def fetch(self, url: str) -> Optional[str]:
        """HTML í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì›¹íŽ˜ì´ì§€ìš©)"""
        try:
            print(f"ðŸŒ Fetching URL: {url}")
            response = await self.session.get(url)
            
            # 4xx, 5xx ì—ëŸ¬ ì²˜ë¦¬
            if response.status_code >= 400:
                print(f"âŒ Fetch Failed [{url}] (Status: {response.status_code})")
                return None
            
            # ì¸ì½”ë”© ìžë™ ê°ì§€ ë° í…ìŠ¤íŠ¸ ë°˜í™˜
            return response.text
            
        except Exception as e:
            print(f"âŒ Fetch Error [{url}]: {e}")
            return None

    async def fetch_binary(self, url: str) -> Optional[bytes]:
        """PDF, DOCX ë“± ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ë¬¸ì„œìš©)"""
        try:
            print(f"â¬‡ï¸ Downloading Binary: {url}")
            response = await self.session.get(url)
            
            if response.status_code == 200:
                return response.content
            else:
                print(f"âŒ Download Failed Status: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ Binary Fetch Error: {e}")
            return None

    async def close(self):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        await self.session.close()

# import hashlib
# from abc import ABC, abstractmethod
# from typing import Optional, Dict, Any
# from curl_cffi.requests import AsyncSession

# class BaseCrawler(ABC):
#     # headers ì¸ìžë¥¼ ë°›ì„ ìˆ˜ ìžˆë„ë¡ ìˆ˜ì •
#     def __init__(self, headers: Optional[Dict[str, str]] = None):
#         # ê¸°ë³¸ í—¤ë” (ëª¨ë“  í¬ë¡¤ëŸ¬ ê³µí†µ)
#         default_headers = {
#             "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
#             "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
#             "Accept-Language": "en-US,en;q=0.9",
#         }
        
#         # íŠ¹ì • í¬ë¡¤ëŸ¬ì—ì„œ í—¤ë”ë¥¼ ì¶”ê°€í–ˆìœ¼ë©´ ë³‘í•© (Update)
#         if headers:
#             default_headers.update(headers)

#         # [ìœ ì§€] impersonate ë²„ì „ì€ ìµœì‹ (chrome120)ìœ¼ë¡œ ìœ ì§€í•´ë„ ë‹¤ë¥¸ ì‚¬ì´íŠ¸ì— í•´ê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
#         self.session = AsyncSession(
#             impersonate="chrome120", 
#             headers=default_headers,
#             timeout=30
#         )

#     def generate_hash(self, content: str) -> str:
#         return hashlib.sha256(content.encode('utf-8')).hexdigest()

#     async def fetch(self, url: str) -> Optional[str]:
#         """HTML í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
#         try:
#             response = await self.session.get(url)
            
#             if response.status_code in [403, 404, 406, 429]:
#                 print(f"âŒ Blocked or Not Found [{url}] (Status: {response.status_code})")
#                 return None
            
#             # [ì¼ë°˜í™”] íŠ¹ì • ì‚¬ì´íŠ¸ ì—ëŸ¬ ì²´í¬ ë¡œì§ ì œê±° (ê° í¬ë¡¤ëŸ¬ì—ì„œ ì²˜ë¦¬ ê¶Œìž¥)
#             return response.text
#         except Exception as e:
#             print(f"âŒ Fetch Error [{url}]: {e}")
#             return None

#     async def fetch_binary(self, url: str) -> Optional[bytes]:
#         try:
#             print(f"â¬‡ï¸ Downloading: {url}")
#             response = await self.session.get(url)
#             if response.status_code == 200:
#                 return response.content
#             else:
#                 print(f"âŒ Download Failed Status: {response.status_code}")
#                 return None
#         except Exception as e:
#             print(f"âŒ Binary Fetch Error: {e}")
#             return None

#     @abstractmethod
#     async def parse(self, html: str, url: str) -> Dict[str, Any]:
#         pass

#     async def close(self):
#         await self.session.close()

# # app/crawler/base.py

# import hashlib
# from abc import ABC, abstractmethod
# from typing import Optional, Dict, Any
# from curl_cffi.requests import AsyncSession

# class BaseCrawler(ABC):
#     def __init__(self):
#         # íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ impersonate ìœ ì§€
#         self.session = AsyncSession(impersonate="chrome110") 

#     def generate_hash(self, content: str) -> str:
#         return hashlib.sha256(content.encode('utf-8')).hexdigest()

#     async def fetch(self, url: str) -> Optional[str]:
#         """HTML í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
#         try:
#             response = await self.session.get(url)
#             if response.status_code in [403, 404]:
#                 print(f"âŒ Blocked or Not Found [{url}]")
#                 return None
#             return response.text
#         except Exception as e:
#             print(f"âŒ Fetch Error [{url}]: {e}")
#             return None

#     # [ì¶”ê°€ë¨] íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ë©”ì„œë“œ
#     async def fetch_binary(self, url: str) -> Optional[bytes]:
#         """PDF ë“± ë°”ì´ë„ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
#         try:
#             print(f"â¬‡ï¸ Downloading: {url}")
#             response = await self.session.get(url)
#             if response.status_code == 200:
#                 return response.content
#             else:
#                 print(f"âŒ Download Failed Status: {response.status_code}")
#                 return None
#         except Exception as e:
#             print(f"âŒ Binary Fetch Error: {e}")
#             return None

#     @abstractmethod
#     async def parse(self, html: str, url: str) -> Dict[str, Any]:
#         pass

#     async def close(self):
#         await self.session.close()