"""
module: embedding_to_vectordb.py
description: ì²­í¬ â†’ ì„ë² ë”© ìƒì„± â†’ Qdrant VectorDB ì €ì¥ (Step 2)
             /data/embeddingsì˜ ì²­í¬ ì •ë³´ë¥¼ ì½ì–´ì„œ
             ì„ë² ë”©ì„ ìƒì„±í•˜ê³  Qdrantì— ì €ì¥í•©ë‹ˆë‹¤
author: AI Agent
created: 2025-11-13
updated: 2025-11-13
dependencies:
    - app.vectorstore.vector_client (Qdrant ì—°ë™)
    - app.ai_pipeline.preprocess.embedding_pipeline (BGE-M3)
    - pathlib, json, logging

ë°ì´í„° íë¦„:
1. /data/embeddings/*_chunks.json ì½ê¸° (ì²­í¬ ì •ë³´)
2. ê° ì²­í¬ ì„ë² ë”© ìƒì„± (BGE-M3, 1024ì°¨ì›)
3. Qdrantì— ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
"""

import sys
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s | %(levelname)-8s | %(message)s"
)
logger = logging.getLogger(__name__)

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent  # /home/minje/remon
EMBEDDINGS_DIR = PROJECT_ROOT / "data" / "embeddings"

# sys.path ë“±ë¡ (ì–´ë””ì„œ ì‹¤í–‰í•´ë„ 'app' ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥í•˜ë„ë¡)
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

logger.info(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
logger.info(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ë””ë ‰í† ë¦¬: {EMBEDDINGS_DIR}")


class EmbeddingToVectorDB:
    """ì²­í¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•´ì„œ Qdrant VectorDBì— ì €ì¥"""

    def __init__(self):
        """ì´ˆê¸°í™” - VectorClientì™€ EmbeddingPipeline ë¡œë“œ"""
        try:
            # Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            from app.vectorstore.vector_client import VectorClient

            self.vc = VectorClient()
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                info = self.vc.get_collection_info()
                logger.info(f"âœ… Qdrant ì—°ê²° ì„±ê³µ: {info}")
            except Exception as conn_e:
                logger.error(f"âŒ Qdrant ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {conn_e}")
                logger.error("   í•´ê²°ë°©ë²•:")
                logger.error("   1. bash scripts/start_qdrant.sh")
                logger.error("   2. docker ps | grep qdrant (ì‹¤í–‰ í™•ì¸)")
                logger.error("   3. .env íŒŒì¼ì— QDRANT_USE_LOCAL=false ì„¤ì •")
                raise
                
        except ImportError as e:
            logger.error(f"âŒ Qdrant ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜: {e}")
            logger.error("   í•´ê²°ë°©ë²•: uv pip install qdrant-client")
            raise
        except Exception as e:
            logger.error(f"âŒ Qdrant ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

        try:
            # ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
            from app.ai_pipeline.preprocess.embedding_pipeline import EmbeddingPipeline

            self.embedder = EmbeddingPipeline(use_sparse=False)
            
            # ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
            test_embedding = self.embedder.embed_single_text("í…ŒìŠ¤íŠ¸")
            if test_embedding and "dense" in test_embedding:
                logger.info("âœ… ì„ë² ë”© ëª¨ë¸(BGE-M3) ë¡œë“œ ì™„ë£Œ")
            else:
                raise RuntimeError("ëª¨ë¸ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë‚˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                
        except ImportError as e:
            logger.error(f"âŒ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜: {e}")
            logger.error("   í•´ê²°ë°©ë²•:")
            logger.error("   uv pip install sentence-transformers FlagEmbedding torch")
            raise
        except Exception as e:
            logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.error("   ê°€ëŠ¥í•œ ì›ì¸:")
            logger.error("   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
            logger.error("   2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            logger.error("   3. torch ë²„ì „ ë¹„í˜¸í™˜")
            raise

        self.results = {
            "start_time": datetime.now().isoformat(),
            "total_chunks": 0,
            "saved_chunks": 0,
            "failed_chunks": 0,
            "files": [],
        }

    def run(self) -> Dict[str, Any]:
        """
        ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰.

        ë‹¨ê³„:
        1. /data/embeddingsì—ì„œ *_chunks.json íŒŒì¼ ìˆ˜ì§‘
        2. ê° íŒŒì¼ì˜ ì²­í¬ ì½ê¸°
        3. ì²­í¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        4. Qdrantì— ì €ì¥ (ë©”íƒ€ë°ì´í„° í¬í•¨)
        5. ê²°ê³¼ ë³´ê³ 
        """
        logger.info("\n" + "=" * 70)
        logger.info("ğŸš€ Step 2: ì²­í¬ ì„ë² ë”© â†’ Qdrant VectorDB ì €ì¥ ì‹œì‘")
        logger.info("=" * 70 + "\n")

        # 1ë‹¨ê³„: ì²­í¬ íŒŒì¼ ìˆ˜ì§‘ ë° ê²€ì¦
        chunk_files = list(EMBEDDINGS_DIR.glob("*_chunks.json"))
        logger.info(f"ğŸ“‹ ë°œê²¬ëœ ì²­í¬ íŒŒì¼: {len(chunk_files)}ê°œ\n")

        if not chunk_files:
            logger.error("âŒ ì²­í¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            logger.error(f"   ê²½ë¡œ: {EMBEDDINGS_DIR}")
            logger.error("   í•´ê²°ë°©ë²•:")
            logger.error("   1. cd /home/minje/remon")
            logger.error("   2. python app/ai_pipeline/preprocess/demo/test_preprocess_demo.py")
            logger.error("   3. ë‹¤ì‹œ ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰")
            return self.results
        
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì¦
        valid_files = []
        for f in chunk_files:
            try:
                with open(f, 'r') as test_f:
                    data = json.load(test_f)
                    if 'chunks' in data and len(data['chunks']) > 0:
                        valid_files.append(f)
                    else:
                        logger.warning(f"âš ï¸  ë¹ˆ ì²­í¬ íŒŒì¼ ìŠ¤í‚µ: {f.name}")
            except Exception as e:
                logger.warning(f"âš ï¸  ì†ìƒëœ íŒŒì¼ ìŠ¤í‚µ: {f.name} - {e}")
        
        chunk_files = valid_files
        logger.info(f"âœ… ìœ íš¨í•œ ì²­í¬ íŒŒì¼: {len(chunk_files)}ê°œ")

        # 2ë‹¨ê³„: ê° íŒŒì¼ ì²˜ë¦¬
        for file_idx, chunk_file in enumerate(chunk_files, 1):
            logger.info(
                f"\n[{file_idx}/{len(chunk_files)}] ğŸ“„ ì²˜ë¦¬ ì¤‘: {chunk_file.name}"
            )
            logger.info("-" * 70)

            try:
                file_result = self._process_chunk_file(chunk_file)
                self.results["files"].append(file_result)

            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                self.results["files"].append(
                    {
                        "filename": chunk_file.name,
                        "status": "failed",
                        "error": str(e),
                    }
                )

        # 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥ ë° ë³´ê³ 
        self.results["end_time"] = datetime.now().isoformat()
        self._print_summary()

        return self.results

    def _process_chunk_file(self, chunk_file: Path) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì²­í¬ íŒŒì¼ ì²˜ë¦¬.

        Args:
            chunk_file: *_chunks.json íŒŒì¼ ê²½ë¡œ

        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        file_result = {
            "filename": chunk_file.name,
            "status": "processing",
            "chunks_processed": 0,
            "chunks_saved": 0,
            "chunks_failed": 0,
        }

        try:
            # ì²­í¬ íŒŒì¼ ì½ê¸°
            with open(chunk_file, "r", encoding="utf-8") as f:
                chunk_data = json.load(f)

            chunks = chunk_data.get("chunks", [])
            num_chunks = len(chunks)
            logger.info(f"   ğŸ“¦ {num_chunks}ê°œ ì²­í¬ ë°œê²¬")

            if not chunks:
                logger.warning("   âš ï¸  ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                file_result["status"] = "empty"
                file_result["reason"] = "no_chunks_found"
                return file_result
            
            # ì²­í¬ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            valid_chunks = []
            for chunk in chunks:
                if chunk.get("text") and len(chunk["text"].strip()) > 10:
                    valid_chunks.append(chunk)
                else:
                    logger.debug(f"   ë¹ˆ ì²­í¬ ìŠ¤í‚µ: {chunk.get('chunk_id', 'unknown')}")
            
            if not valid_chunks:
                logger.warning("   âš ï¸  ìœ íš¨í•œ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤")
                file_result["status"] = "empty"
                return file_result
            
            chunks = valid_chunks
            num_chunks = len(chunks)
            logger.info(f"   âœ… ìœ íš¨í•œ ì²­í¬: {num_chunks}ê°œ")

            # ê° ì²­í¬ ì²˜ë¦¬
            chunk_texts = []
            chunk_metadatas = []
            chunk_ids = []

            for chunk in chunks:
                chunk_id = chunk.get("chunk_id", "unknown")
                text = chunk.get("text", "")

                chunk_ids.append(chunk_id)
                chunk_texts.append(text)

                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    "chunk_id": chunk_id,
                    "section": chunk.get("section", ""),
                    "section_title": chunk.get("section_title", ""),
                    "subsection": chunk.get("subsection", ""),
                    "hierarchy_path": chunk.get("hierarchy_path", ""),
                    "hierarchy_depth": chunk.get("hierarchy_depth", 0),
                    "has_table": chunk.get("has_table", False),
                    "tokens_estimate": chunk.get("tokens_estimate", 0),
                    "source_file": chunk_file.stem,  # íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
                }
                chunk_metadatas.append(metadata)

            # ì„ë² ë”© ìƒì„±
            logger.info(f"   ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘... ({num_chunks}ê°œ)")
            embeddings_result = self.embedder.embed_texts(chunk_texts, normalize=True)
            embeddings = embeddings_result.get("dense", [])
            logger.info(f"   âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ")

            # Qdrantì— ì €ì¥
            logger.info(f"   ğŸ’¾ Qdrantì— ì €ì¥ ì¤‘...")
            try:
                upserted_count = self.vc.upsert(
                    ids=chunk_ids,
                    embeddings=embeddings,
                    metadatas=chunk_metadatas,
                    documents=chunk_texts,
                )
                logger.info(f"   âœ“ {upserted_count}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ")
            except Exception as qdrant_e:
                logger.error(f"   âŒ Qdrant ì €ì¥ ì‹¤íŒ¨: {qdrant_e}")
                logger.error("   ê°€ëŠ¥í•œ ì›ì¸:")
                logger.error("   1. Qdrant ì„œë²„ ì—°ê²° ëŠì–´ì§")
                logger.error("   2. ë©”ëª¨ë¦¬ ë¶€ì¡±")
                logger.error("   3. ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜")
                raise qdrant_e

            # ê²°ê³¼ ì—…ë°ì´íŠ¸
            file_result["status"] = "success"
            file_result["chunks_processed"] = num_chunks
            file_result["chunks_saved"] = upserted_count
            file_result["chunks_failed"] = num_chunks - upserted_count

            self.results["total_chunks"] += num_chunks
            self.results["saved_chunks"] += upserted_count
            self.results["failed_chunks"] += num_chunks - upserted_count

        except Exception as e:
            logger.error(f"   âŒ ì˜¤ë¥˜: {str(e)}")
            file_result["status"] = "failed"
            file_result["error"] = str(e)

        return file_result

    def _print_summary(self) -> None:
        """ìµœì¢… ìš”ì•½ ì¶œë ¥"""
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“Š Step 2 ì™„ë£Œ ìš”ì•½")
        logger.info("=" * 70)
        logger.info(f"ì´ ì²­í¬: {self.results['total_chunks']}ê°œ")
        logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: {self.results['saved_chunks']}ê°œ")
        logger.info(f"âŒ ì €ì¥ ì‹¤íŒ¨: {self.results['failed_chunks']}ê°œ")
        logger.info(f"\nğŸ“ Qdrant ìœ„ì¹˜:")
        logger.info(f"   - ì„œë²„: http://localhost:6333")
        logger.info(f"   - ëŒ€ì‹œë³´ë“œ: http://localhost:6333/dashboard")
        logger.info(f"   - ì €ì¥ ê²½ë¡œ: /data/qdrant (ë„ì»¤ ë³¼ë¥¨)")
        logger.info(f"\nâœ¨ ë‹¤ìŒ ë‹¨ê³„:")
        logger.info(f"   1. Qdrant ëŒ€ì‹œë³´ë“œì—ì„œ ë°ì´í„° í™•ì¸")
        logger.info(f"   2. python scripts/test_rag_query.py ì‹¤í–‰")
        logger.info(f"   3. RAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n")


if __name__ == "__main__":
    try:
        runner = EmbeddingToVectorDB()
        results = runner.run()
    except Exception as e:
        logger.error(f"\nâŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        sys.exit(1)
