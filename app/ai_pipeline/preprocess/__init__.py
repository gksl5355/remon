"""
Preprocessing entrypoints exposed to the LangGraph pipeline.
"""

from __future__ import annotations

import asyncio
import logging
from typing import Any, Dict, List, Optional, TYPE_CHECKING

from app.ai_pipeline.state import AppState, PreprocessRequest, PreprocessSummary

if TYPE_CHECKING:  # pragma: no cover
    from app.ai_pipeline.preprocess.preprocess_orchestrator import (
        PreprocessOrchestrator,
    )

logger = logging.getLogger(__name__)

_orchestrator: "PreprocessOrchestrator | None" = None


def _get_orchestrator() -> PreprocessOrchestrator:
    """Lazy ì´ˆê¸°í™”ëœ PreprocessOrchestrator ë°˜í™˜."""
    global _orchestrator
    if _orchestrator is None:
        from app.ai_pipeline.preprocess.preprocess_orchestrator import (
            PreprocessOrchestrator,
        )

        _orchestrator = PreprocessOrchestrator()
    return _orchestrator


async def _run_orchestrator(pdf_path: str) -> Dict[str, Any]:
    """Blocking ì „ì²˜ë¦¬ ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹)."""
    orchestrator = _get_orchestrator()
    return await asyncio.to_thread(orchestrator.process_pdf, pdf_path)


async def _run_vision_orchestrator(
    pdf_path: str, vision_config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Vision Pipeline ì‹¤í–‰.

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        vision_config: Vision ì„¤ì • ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            - api_key: OpenAI API í‚¤ (í•„ìˆ˜)
            - max_concurrency: ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜ (ê¸°ë³¸ê°’: 3)
            - token_budget: í† í° ì˜ˆì‚° (ê¸°ë³¸ê°’: None)
            - request_timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ ì´ˆ (ê¸°ë³¸ê°’: 120)
            - retry_max_attempts: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 2)
            - retry_backoff_seconds: ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ ì´ˆ (ê¸°ë³¸ê°’: 1.0)
            - ê¸°íƒ€ ì„¤ì •ë“¤...
    """
    from app.ai_pipeline.preprocess.vision_orchestrator import VisionOrchestrator
    from app.ai_pipeline.preprocess.config import PreprocessConfig

    # LangSmith ì´ˆê¸°í™”
    PreprocessConfig.setup_langsmith()

    # vision_configê°€ ì œê³µë˜ë©´ ì¸ìë¡œ ì „ë‹¬, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    if vision_config:
        orchestrator = VisionOrchestrator(**vision_config)
    else:
        orchestrator = VisionOrchestrator()
    return await asyncio.to_thread(orchestrator.process_pdf, pdf_path)


def _resolve_pdf_paths(state: AppState) -> List[str]:
    """
    PDF ê²½ë¡œ ê²°ì • ìš°ì„ ìˆœìœ„:
    1. state["preprocess_request"]["pdf_paths"] (ì§ì ‘ ì§€ì •)
    2. state["preprocess_request"]["load_from_s3"] = True (S3 ìë™ ë¡œë“œ)
    3. ë¹ˆ ë¦¬ìŠ¤íŠ¸ (ìŠ¤í‚µ)
    """
    request: PreprocessRequest | None = state.get("preprocess_request")

    if not request:
        return []

    # 1. ì§ì ‘ ì§€ì •ëœ ê²½ë¡œ
    pdf_paths = request.get("pdf_paths", [])
    if pdf_paths:
        return pdf_paths

    # 2. S3 ìë™ ë¡œë“œ
    if request.get("load_from_s3"):
        from app.ai_pipeline.preprocess.s3_loader import load_today_regulations

        target_date = request.get("s3_date")  # YYYYMMDD or None
        logger.info("ğŸ“¥ S3ì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œ ê·œì œ íŒŒì¼ ìë™ ë¡œë“œ")

        s3_paths = load_today_regulations(target_date)
        return s3_paths

    return []


async def preprocess_node(state: AppState) -> AppState:
    """
    LangGraph preprocess node.

    ê¸°ëŒ€ ì…ë ¥:
        state["preprocess_request"] = {
            "pdf_paths": ["/path/a.pdf", ...],
            "product_info": {...},  # ì„ íƒ ì‚¬í•­
            "use_vision_pipeline": bool,  # Trueë©´ Vision Pipeline ì‚¬ìš©
            "vision_config": {  # ì„ íƒ ì‚¬í•­, Vision Pipeline ì„¤ì •
                "api_key": "sk-...",  # í•„ìˆ˜
                "max_concurrency": 3,
                "token_budget": 100000,
                "request_timeout": 120,
                "retry_max_attempts": 2,
                "retry_backoff_seconds": 1.0,
                # ê¸°íƒ€ ì„¤ì •ë“¤...
            }
        }
    ì¶œë ¥:
        state["preprocess_results"]  # ê° PDF ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        state["preprocess_summary"]  # ì§„í–‰ ìƒíƒœ ë©”íƒ€ë°ì´í„°
        state["vision_extraction_result"]  # Vision Pipeline ì‚¬ìš© ì‹œ
        state["graph_data"]  # Vision Pipeline ì‚¬ìš© ì‹œ
        state["dual_index_summary"]  # Vision Pipeline ì‚¬ìš© ì‹œ
    """

    # PDF ê²½ë¡œ ê²°ì • (ì§ì ‘ ì§€ì • ë˜ëŠ” S3 ìë™ ë¡œë“œ)
    pdf_paths: List[str] = _resolve_pdf_paths(state)

    request: PreprocessRequest | None = state.get("preprocess_request") or {}
    if not pdf_paths:
        logger.info("preprocess_node skipped â€“ pdf_paths ë¹„ì–´ìˆìŒ")
        summary = {
            "status": "skipped",
            "processed_count": 0,
            "succeeded": 0,
            "failed": 0,
            "reason": "pdf_paths missing",
        }
        state["preprocess_summary"] = summary
        return state

    # Vision Pipeline ì‚¬ìš© ì—¬ë¶€ í™•ì¸
    use_vision = request.get("use_vision_pipeline", False)

    logger.info(
        "preprocess_node ì‹œì‘: %dê°œ PDF (Vision: %s)", len(pdf_paths), use_vision
    )

    processed_results: List[Dict[str, Any]] = []
    success_count = 0
    all_vision_results = []
    all_graph_data = {"nodes": [], "edges": []}
    all_index_summaries = []

    # Vision Pipeline ì„¤ì • (preprocess_requestì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    vision_config = request.get("vision_config") if use_vision else None

    for pdf_path in pdf_paths:
        try:
            if use_vision:
                result = await _run_vision_orchestrator(
                    pdf_path, vision_config=vision_config
                )
            else:
                result = await _run_orchestrator(pdf_path)

            result.setdefault("pdf_path", pdf_path)

            # ğŸ”¥ DBì— ì €ì¥í•˜ê³  regulation_id ì¶”ê°€
            if result.get("status") == "success" and use_vision:
                from app.core.repositories.regulation_repository import (
                    RegulationRepository,
                )
                from app.core.database import AsyncSessionLocal

                async with AsyncSessionLocal() as session:
                    repo = RegulationRepository()
                    try:
                        regulation = await repo.create_from_vision_result(
                            session, result
                        )
                        await session.commit()
                        result["regulation_id"] = regulation.regulation_id
                        logger.info(
                            f"âœ… DB ì €ì¥ ì™„ë£Œ: regulation_id={regulation.regulation_id}"
                        )
                        
                        # ğŸ”‘ change_context ìë™ ì±„ìš°ê¸° (ë³€ê²½ ê°ì§€ìš©)
                        if request.get("enable_change_detection"):
                            state["change_context"] = {
                                "new_regulation_id": regulation.regulation_id,
                                "new_regul_data": result,
                            }
                            logger.info("âœ… change_context ìë™ ì„¤ì • ì™„ë£Œ")
                    except Exception as e:
                        await session.rollback()
                        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")

            processed_results.append(result)

            if result.get("status") == "success":
                success_count += 1

                # Vision Pipeline ê²°ê³¼ ìˆ˜ì§‘
                if use_vision:
                    all_vision_results.extend(
                        result.get("vision_extraction_result", [])
                    )

                    graph_data = result.get("graph_data", {})
                    all_graph_data["nodes"].extend(graph_data.get("nodes", []))
                    all_graph_data["edges"].extend(graph_data.get("edges", []))

                    if result.get("dual_index_summary"):
                        all_index_summaries.append(result["dual_index_summary"])

        except Exception as exc:  # pragma: no cover - defensive guard
            logger.exception("PDF ì „ì²˜ë¦¬ ì‹¤íŒ¨: %s", pdf_path)
            processed_results.append(
                {
                    "pdf_path": pdf_path,
                    "status": "error",
                    "error": str(exc),
                }
            )

    fail_count = len(processed_results) - success_count
    summary_status: str
    if success_count == len(processed_results):
        summary_status = "completed"
    elif success_count == 0:
        summary_status = "error"
    else:
        summary_status = "partial"

    state["preprocess_results"] = processed_results
    summary: PreprocessSummary = {
        "status": summary_status,
        "processed_count": len(processed_results),
        "succeeded": success_count,
        "failed": fail_count,
        "reason": None,
    }
    state["preprocess_summary"] = summary

    # Vision Pipeline ê²°ê³¼ ì €ì¥
    if use_vision and all_vision_results:
        state["vision_extraction_result"] = all_vision_results
        state["graph_data"] = all_graph_data
        state["dual_index_summary"] = {
            "total_chunks": sum(s.get("qdrant_chunks", 0) for s in all_index_summaries),
            "total_nodes": len(all_graph_data["nodes"]),
            "total_edges": len(all_graph_data["edges"]),
            "summaries": all_index_summaries,
        }

    # product_infoê°€ Preprocess ë‹¨ê³„ì—ì„œ ì „ë‹¬ë˜ëŠ” ê²½ìš° ìƒíƒœì— ë°˜ì˜
    if request.get("product_info"):
        state["product_info"] = request["product_info"]

    logger.info(
        "preprocess_node ì™„ë£Œ: success=%d, failed=%d",
        success_count,
        fail_count,
    )

    # ë³€ê²½ ê°ì§€ í™œì„±í™” ì‹œ regulation ë©”íƒ€ë°ì´í„° ì¶”ê°€
    if request.get("enable_change_detection") and processed_results:
        first_result = processed_results[0]
        if first_result.get("status") == "success" and use_vision:
            vision_pages = first_result.get("vision_extraction_result", [])
            if vision_pages:
                structure = vision_pages[0].get("structure", {})
                metadata = structure.get("metadata") or {}
                state["regulation"] = {
                    "country": metadata.get("jurisdiction_code", "US"),
                    "title": metadata.get("title", "Unknown Regulation"),
                    "effective_date": metadata.get("effective_date"),
                    "citation_code": metadata.get("citation_code"),
                    "authority": metadata.get("authority"),
                    "regulation_id": first_result.get("regulation_id"),
                }
                logger.info("âœ… regulation ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ")

    return state


__all__ = ["preprocess_node"]
