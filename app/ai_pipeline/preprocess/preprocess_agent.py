import os
import json
from app.ai_pipeline.preprocess.loader import DocumentLoader
from app.ai_pipeline.llm_engine import LLMEngine

class PreprocessAgent:
    def __init__(self):
        self.llm_engine = LLMEngine()

    async def run(self, file_path: str, meta_data: dict):
        print(f"\nğŸ¤– [Preprocess] ì „ì²˜ë¦¬ ì‹œì‘: {os.path.basename(file_path)}")
        
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
            return

        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (Loader)
        extracted_text = await DocumentLoader.load(file_path)
        if not extracted_text:
            print("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (ë¹ˆ íŒŒì¼)")
            return

        print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(extracted_text)}ì)")

        # 2. AI ë¶„ì„ (LLM Engine) í˜¸ì¶œ
        print("ğŸš€ AI ë¶„ì„ ì—”ì§„ìœ¼ë¡œ ë°ì´í„° ì „ì†¡...")
        analysis_result = await self.llm_engine.analyze_regulation(
            text_content=extracted_text, 
            country_code=meta_data.get("country_code", "ZZ")
        )

        # 3. ê²°ê³¼ ì¶œë ¥ (ì—¬ê¸°ì„œ JSONì´ ì½˜ì†”ì— ë³´ì—¬ì•¼ í•¨!)
        if analysis_result:
            print("\n" + "="*40)
            print("ğŸ“Š [AI ë¶„ì„ ê²°ê³¼ (JSON)]")
            print("="*40)
            print(json.dumps(analysis_result, indent=2, ensure_ascii=False))
            print("="*40 + "\n")
        else:
            print("âš ï¸ AI ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# import os
# from app.ai_pipeline.preprocess.loader import DocumentLoader

# class PreprocessAgent:
#     async def run(self, file_path: str, meta_data: dict):
#         """
#         ì €ì¥ëœ íŒŒì¼ì„ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
#         [ìˆ˜ì •] DocumentLoaderê°€ ë¹„ë™ê¸°ë¡œ ë³€ê²½ë¨ì— ë”°ë¼ await í‚¤ì›Œë“œ ì¶”ê°€
#         """
#         print(f"\nğŸ¤– [Preprocess Agent] ì‘ë™ ì‹œì‘")
#         print(f"ğŸ“„ Target File: {file_path}")
        
#         if not os.path.exists(file_path):
#             print(f"âŒ Error: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ({file_path})")
#             return None

#         # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (Loader ì‚¬ìš©) - ë¹„ë™ê¸° í˜¸ì¶œ
#         extracted_text = await DocumentLoader.load(file_path)
        
#         if not extracted_text:
#             print("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ë‚´ìš©ì…ë‹ˆë‹¤.")
#             return None

#         print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(extracted_text)}ì)")
        
#         # 2. ê²°ê³¼ ë°˜í™˜ (ì¶”í›„ LangGraph State ë˜ëŠ” DB ì—…ë°ì´íŠ¸ìš©)
#         # ì—¬ê¸°ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§€ê³  'ìš”ì•½'ì´ë‚˜ 'ë²ˆì—­' ì—ì´ì „íŠ¸ë¡œ ë„˜ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#         result = {
#             "status": "success",
#             "file_path": file_path,
#             "meta_data": meta_data,
#             "extracted_text": extracted_text,
#             "char_count": len(extracted_text)
#         }
        
#         return result

# import os
# from app.ai_pipeline.preprocess.loader import DocumentLoader

# class PreprocessAgent:
#     async def run(self, file_path: str, meta_data: dict):
#         """
#         ì €ì¥ëœ íŒŒì¼ì„ ë¡œë“œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
#         """
#         print(f"\nğŸ¤– [Preprocess Agent] ì‘ë™ ì‹œì‘")
#         print(f"ğŸ“„ Target File: {file_path}")
        
#         if not os.path.exists(file_path):
#             print(f"âŒ Error: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ ({file_path})")
#             return None

#         # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (Loader ì‚¬ìš©)
#         extracted_text = DocumentLoader.load(file_path)
        
#         if not extracted_text:
#             print("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ë‚´ìš©ì…ë‹ˆë‹¤.")
#             return None

#         print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(extracted_text)}ì)")
        
#         # 2. ê²°ê³¼ ë°˜í™˜ (ì¶”í›„ LangGraph Stateì— ë“¤ì–´ê°ˆ ë‚´ìš©)
#         return {
#             "status": "success",
#             "file_path": file_path,
#             "meta_data": meta_data,
#             "extracted_text": extracted_text  # ì¶”ì¶œëœ ë³¸ë¬¸
#         }