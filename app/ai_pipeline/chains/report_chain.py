## âœ… ì „ì²´ ìˆ˜ì •ëœ report_chain.py

"""
ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± LLM Chain
ê·œì œ ë³€ê²½ + ì˜í–¥í‰ê°€ â†’ ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±

Author: ë‚¨ì§€ìˆ˜ (BE2 - Database Engineer)
"""

from typing import Dict, Any, Optional
import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser


# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class ReportGeneratorChain:
    """
    ê·œì œ ë³€ê²½ ë‚´ìš©ê³¼ ì˜í–¥í‰ê°€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” LLM Chain
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ê·œì œ ë³€ê²½ ì‚¬í•­ì˜ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
    - ì˜í–¥ë„ ì ìˆ˜ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ë¶„ì„
    - ê²½ì˜ì§„ì„ ìœ„í•œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ì œì‹œ
    """
    
    def __init__(
        self, 
        model: str = "gpt-4o-mini",
        temperature: float = 0.3,
        max_tokens: int = 2000
    ):
        """
        Chain ì´ˆê¸°í™”
        
        Args:
            model: ì‚¬ìš©í•  LLM ëª¨ë¸ëª…
            temperature: ìƒì„± ë‹¤ì–‘ì„± (0~1, ë‚®ì„ìˆ˜ë¡ ì¼ê´€ì )
            max_tokens: ìµœëŒ€ ìƒì„± í† í° ìˆ˜
        """
        self.model_name = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
        self.prompt = self._build_prompt_template()
        
        # Chain êµ¬ì„±
        self.chain = self.prompt | self.llm | StrOutputParser()
        
        logger.info(f"ReportGeneratorChain ì´ˆê¸°í™” ì™„ë£Œ - ëª¨ë¸: {model}")
    
    def _build_prompt_template(self) -> ChatPromptTemplate:
        """
        ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
        
        Returns:
            ChatPromptTemplate: LangChain í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        """
        return ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë‹´ë°° ê·œì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê·œì œ ë³€ê²½ ë‚´ìš©ê³¼ ì œí’ˆë³„ ì˜í–¥í‰ê°€ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ **ê²½ì˜ì§„ì„ ìœ„í•œ ìš”ì•½ ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì„ë¬´ì…ë‹ˆë‹¤.

**ì‘ì„± ì›ì¹™:**
1. **ê°„ê²°ì„±**: í•µì‹¬ë§Œ ì¶”ë ¤ì„œ A4 1ì¥ ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±
2. **ëª…í™•ì„±**: ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
3. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì¡°ì¹˜ì‚¬í•­ ì œì‹œ
4. **ìš°ì„ ìˆœìœ„**: ê³ ìœ„í—˜ ì œí’ˆ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ìˆ 

**ë¦¬í¬íŠ¸ êµ¬ì¡°:**
1. ê·œì œ ë³€ê²½ í•µì‹¬ ìš”ì•½ (3ì¤„ ì´ë‚´)
2. ì˜í–¥ë„ ë¶„ì„ (ê³ /ì¤‘/ì €ìœ„í—˜ ì œí’ˆ í˜„í™©)
3. ì¦‰ì‹œ ëŒ€ì‘ì´ í•„ìš”í•œ ì•¡ì…˜ ì•„ì´í…œ (ìš°ì„ ìˆœìœ„ìˆœ)
4. ì˜ˆìƒ ë¦¬ìŠ¤í¬ ë° ê¶Œê³ ì‚¬í•­

**í†¤ì•¤ë§¤ë„ˆ:**
- ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰½ê²Œ
- ì‚¬ì‹¤ ê¸°ë°˜ ê°ê´€ì  ë¶„ì„
- ê¸ì •ì ì´ì§€ë§Œ ìœ„í—˜ì€ ëª…í™•íˆ ì „ë‹¬"""),
            
            ("human", """ë‹¤ìŒ ê·œì œ ë³€ê²½ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

# ğŸ“‹ ê·œì œ ë³€ê²½ ë‚´ìš©
{regulation_text}

# ğŸ“Š ì˜í–¥í‰ê°€ ê²°ê³¼
{impact_summary}

# ğŸŒ ê·œì œ ë©”íƒ€ë°ì´í„°
- **êµ­ê°€**: {country}
- **ì‹œí–‰ì¼**: {effective_date}
- **ê·œì œ ID**: {regulation_id}

---

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²½ì˜ì§„ìš© ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë˜, í—¤ë”ëŠ” ##ë¶€í„° ì‹œì‘í•˜ì„¸ìš”.""")
        ])
    
    async def generate(
        self,
        regulation_text: str,
        impact_scores: Dict[str, float],
        metadata: Dict[str, Any]
    ) -> str:
        """
        ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ë™ê¸°)
        
        Args:
            regulation_text: ê·œì œ ë³€ê²½ ë‚´ìš© í…ìŠ¤íŠ¸
            impact_scores: ì œí’ˆë³„ ì˜í–¥ë„ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
            metadata: ë©”íƒ€ë°ì´í„° (êµ­ê°€, ì‹œí–‰ì¼ ë“±)
        
        Returns:
            str: ìƒì„±ëœ ìš”ì•½ ë¦¬í¬íŠ¸ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
        
        Raises:
            Exception: LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        logger.info(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ - ì œí’ˆ ìˆ˜: {len(impact_scores)}")
        
        # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        impact_summary = self._format_impact_scores(impact_scores)
        
        # í”„ë¡¬í”„íŠ¸ ì…ë ¥ êµ¬ì„±
        prompt_input = {
            "regulation_text": self._truncate_text(regulation_text, max_length=1500),
            "impact_summary": impact_summary,
            "country": metadata.get("country_code", "N/A"),
            "effective_date": metadata.get("effective_date", "N/A"),
            "regulation_id": metadata.get("regulation_id", "N/A")
        }
        
        try:
            # LLM Chain ì‹¤í–‰
            report = await self.chain.ainvoke(prompt_input)
            
            logger.info(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(report)}")
            return report
        
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def generate_sync(
        self,
        regulation_text: str,
        impact_scores: Dict[str, float],
        metadata: Dict[str, Any]
    ) -> str:
        """
        ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± (ë™ê¸°)
        
        Args:
            regulation_text: ê·œì œ ë³€ê²½ ë‚´ìš© í…ìŠ¤íŠ¸
            impact_scores: ì œí’ˆë³„ ì˜í–¥ë„ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
            metadata: ë©”íƒ€ë°ì´í„°
        
        Returns:
            str: ìƒì„±ëœ ìš”ì•½ ë¦¬í¬íŠ¸
        """
        logger.info(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (ë™ê¸°) - ì œí’ˆ ìˆ˜: {len(impact_scores)}")
        
        impact_summary = self._format_impact_scores(impact_scores)
        
        prompt_input = {
            "regulation_text": self._truncate_text(regulation_text, max_length=1500),
            "impact_summary": impact_summary,
            "country": metadata.get("country_code", "N/A"),
            "effective_date": metadata.get("effective_date", "N/A"),
            "regulation_id": metadata.get("regulation_id", "N/A")
        }
        
        try:
            report = self.chain.invoke(prompt_input)
            logger.info(f"ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(report)}")
            return report
        
        except Exception as e:
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _format_impact_scores(self, impact_scores: Dict[str, float]) -> str:
        """ì˜í–¥ë„ ì ìˆ˜ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        
        high_risk = [(pid, score) for pid, score in impact_scores.items() if score >= 0.7]
        medium_risk = [(pid, score) for pid, score in impact_scores.items() if 0.3 <= score < 0.7]
        low_risk = [(pid, score) for pid, score in impact_scores.items() if score < 0.3]
        
        high_risk.sort(key=lambda x: x[1], reverse=True)
        medium_risk.sort(key=lambda x: x[1], reverse=True)
        low_risk.sort(key=lambda x: x[1], reverse=True)
        
        lines = []
        
        lines.append(f"**ğŸ”´ ê³ ìœ„í—˜ ì œí’ˆ: {len(high_risk)}ê°œ**")
        if high_risk:
            for pid, score in high_risk[:5]:
                lines.append(f"  - ì œí’ˆ ID {pid}: ì˜í–¥ë„ {score:.3f}")
            if len(high_risk) > 5:
                lines.append(f"  - ... ì™¸ {len(high_risk) - 5}ê°œ")
        else:
            lines.append("  - í•´ë‹¹ ì—†ìŒ")
        
        lines.append("")
        
        lines.append(f"**ğŸŸ¡ ì¤‘ìœ„í—˜ ì œí’ˆ: {len(medium_risk)}ê°œ**")
        if medium_risk:
            for pid, score in medium_risk[:3]:
                lines.append(f"  - ì œí’ˆ ID {pid}: ì˜í–¥ë„ {score:.3f}")
            if len(medium_risk) > 3:
                lines.append(f"  - ... ì™¸ {len(medium_risk) - 3}ê°œ")
        else:
            lines.append("  - í•´ë‹¹ ì—†ìŒ")
        
        lines.append("")
        lines.append(f"**ğŸŸ¢ ì €ìœ„í—˜ ì œí’ˆ: {len(low_risk)}ê°œ**")
        lines.append("  - ì˜í–¥ ë¯¸ë¯¸, ëª¨ë‹ˆí„°ë§ ìˆ˜ì¤€")
        
        return "\n".join(lines)
    
    def _truncate_text(self, text: str, max_length: int = 1500) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ê¸¸ì´ë¡œ ìë¥´ê¸°"""
        if len(text) <= max_length:
            return text
        
        truncated = text[:max_length].rsplit(' ', 1)[0]
        return truncated + "..."
    
    def update_model(self, model: str, temperature: Optional[float] = None):
        """ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.model_name = model
        if temperature is not None:
            self.temperature = temperature
        
        self.llm = ChatOpenAI(
            model=model,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )
        
        self.chain = self.prompt | self.llm | StrOutputParser()
        logger.info(f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ - ìƒˆ ëª¨ë¸: {model}")


if __name__ == "__main__":
    """ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ"""
    import asyncio
    
    async def test_chain():
        chain = ReportGeneratorChain(model="gpt-4o-mini", temperature=0.3)
        
        test_regulation = """
        ë¯¸êµ­ FDAëŠ” 2026ë…„ 1ì›” 1ì¼ë¶€í„° ë‹´ë°° ì œí’ˆì˜ ë‹ˆì½”í‹´ í•¨ëŸ‰ ìƒí•œì„ ì„ 
        í˜„í–‰ 1.2mgì—ì„œ 0.9mgìœ¼ë¡œ ê°•í™”í•©ë‹ˆë‹¤.
        """
        
        test_impact_scores = {
            "product_001": 0.92,
            "product_002": 0.85,
            "product_003": 0.45
        }
        
        test_metadata = {
            "country_code": "US",
            "effective_date": "2026-01-01",
            "regulation_id": 12345
        }
        
        print("=== LLM Chain í…ŒìŠ¤íŠ¸ ì‹œì‘ ===\n")
        report = await chain.generate(test_regulation, test_impact_scores, test_metadata)
        print(report)
    
    asyncio.run(test_chain())