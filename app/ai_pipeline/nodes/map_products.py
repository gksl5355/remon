"""
map_products.py
ê²€ìƒ‰ TOOL(ë¯¸ì •) + LLM ë§¤í•‘ Node
search_toolì˜ ì¸í„°í˜ì´ìŠ¤ëŠ” ì•„ì§ ê²°ì •ë˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì—
í˜¸ì¶œë¶€ëŠ” wrapperë¡œ ê°ì‹¸ê³  TODOë¡œ ë§ˆí‚¹í•´ë‘”ë‹¤.
"""

import json
from typing import Dict, List, Any

from state import (
    ProductInfo,
    RetrievedChunk,
    RetrievalResult,
    MappingItem,
    MappingParsed,
    MappingResults,
)

from prompts.mapping_prompt import MAPPING_PROMPT


class MappingNode:
    """
    ê²€ìƒ‰ + ë§¤í•‘ í†µí•© Node
    - ê²€ìƒ‰ì€ ì™¸ë¶€ search_tool(TOOL CALL)ë¡œ ì²˜ë¦¬
    - search_tool ì‹œê·¸ë‹ˆì²˜ëŠ” ì•„ì§ ë¯¸ì •ì´ë¯€ë¡œ wrapper ë‚´ë¶€ TODO ì²˜ë¦¬
    """

    def __init__(
        self,
        llm_client,
        search_tool,  # ğŸ”¥ LangGraph TOOL ìì²´
        top_k: int = 5,
        alpha: float = 0.7,  # ğŸ”¥ hybrid dense/sparse ë¹„ìœ¨
    ):
        self.llm = llm_client
        self.search_tool = search_tool
        self.top_k = top_k
        self.alpha = alpha  # ğŸ”¥ dynamic hybrid weight

    # ----------------------------------------------------------------------
    # 1) ê²€ìƒ‰ TOOL í˜¸ì¶œ wrapper (search_tool ì¸í„°í˜ì´ìŠ¤ í™•ì •ë˜ë©´ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •)
    # ----------------------------------------------------------------------
    async def _run_search(
        self,
        product_id: str,
        feature_name: str,
        feature_value: Any,
        feature_unit: str | None,
    ) -> RetrievalResult:
        """
        ê²€ìƒ‰ TOOLì„ í˜¸ì¶œí•˜ëŠ” wrapper.
        search_toolì˜ ìµœì¢… ì¸í„°í˜ì´ìŠ¤ê°€ í™•ì •ë˜ë©´
        ì´ í•¨ìˆ˜ë§Œ ìˆ˜ì •í•˜ë©´ ì „ì²´ ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì—°ë™ë¨.

        âœ” hybrid alpha ì ìš©
        âœ” top_k ì ìš©
        âœ” feature ì •ë³´ ì „ë‹¬
        """

        # ------------------------------------------------------------------
        # ğŸ”¥ TODO(remon-ai):
        #   search_tool.pyê°€ ì™„ì„±ë˜ë©´ ì•„ë˜ í˜¸ì¶œë¶€ë¥¼ í•´ë‹¹ ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
        #
        #   ì˜ˆì‹œ ì˜ˆìƒ í˜•íƒœ (ì™„ì„±ë˜ë©´ ì´ ë¶€ë¶„ì„ ìˆ˜ì •)
        #
        #   result = await self.search_tool(
        #       product_id=product_id,
        #       feature_name=feature_name,
        #       feature_value=feature_value,
        #       feature_unit=feature_unit,
        #       top_k=self.top_k,
        #       alpha=self.alpha,
        #   )
        #
        #   return RetrievalResult(**result)
        # ------------------------------------------------------------------

        # ì„ì‹œ placeholder (dummy í˜•íƒœ)
        result = {
            "product_id": product_id,
            "feature_name": feature_name,
            "feature_value": feature_value,
            "feature_unit": feature_unit,
            "candidates": [],  # ë‚˜ì¤‘ì— TOOL ì¶œë ¥ìœ¼ë¡œ ì±„ì›Œì§ˆ ê²ƒ
        }

        return result

    # ----------------------------------------------------------------------
    # 2) ë§¤í•‘ í”„ë¡¬í”„íŠ¸ ìƒì„± (local ì²˜ë¦¬)
    # ----------------------------------------------------------------------
    def _build_prompt(self, feature_name, feature_value, feature_unit, chunk_text):
        feature = {
            "name": feature_name,
            "value": feature_value,
            "unit": feature_unit,
        }
        return MAPPING_PROMPT.format(
            feature=json.dumps(feature, ensure_ascii=False),
            chunk=chunk_text,
        )

    # ----------------------------------------------------------------------
    # 3) LLM ë§¤í•‘ í˜¸ì¶œ
    # ----------------------------------------------------------------------
    async def _call_llm(self, prompt: str) -> Dict:
        try:
            res = await self.llm.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
            )
            return json.loads(res.choices[0].message.content)

        except Exception:
            return {
                "applies": False,
                "required_value": None,
                "current_value": None,
                "gap": None,
                "parsed": {
                    "category": None,
                    "requirement_type": "other",
                    "condition": None,
                },
            }

    # ----------------------------------------------------------------------
    # 4) LangGraph Node entrypoint
    # ----------------------------------------------------------------------
    async def run(self, state: Dict) -> Dict:
        product: ProductInfo = state["product_info"]
        product_id = product["product_id"]
        features = product["features"]
        units = product.get("feature_units", {})

        mapping_results: List[MappingItem] = []

        # ğŸ”¥ featureë³„ë¡œ ê²€ìƒ‰ TOOL â†’ ë§¤í•‘
        for feature_name, value in features.items():
            unit = units.get(feature_name)

            # -----------------------------------------
            # a) ê²€ìƒ‰ TOOL í˜¸ì¶œ
            # -----------------------------------------
            retrieval: RetrievalResult = await self._run_search(
                product_id, feature_name, value, unit
            )

            # -----------------------------------------
            # b) LLM ë§¤í•‘ ìˆ˜í–‰
            # -----------------------------------------
            for cand in retrieval["candidates"]:
                prompt = self._build_prompt(
                    feature_name, value, unit, cand["chunk_text"]
                )
                llm_out = await self._call_llm(prompt)

                parsed: MappingParsed = llm_out.get("parsed", {})

                mapping_results.append(
                    MappingItem(
                        product_id=product_id,
                        feature_name=feature_name,
                        applies=llm_out["applies"],
                        required_value=llm_out["required_value"],
                        current_value=llm_out["current_value"],
                        gap=llm_out["gap"],
                        regulation_chunk_id=cand["chunk_id"],
                        regulation_summary=cand["chunk_text"][:120],
                        regulation_meta=cand["metadata"],
                        parsed=parsed,
                    )
                )

        # -----------------------------------------
        # c) ì „ì—­ State ì—…ë°ì´íŠ¸
        # -----------------------------------------
        state["mapping"] = MappingResults(
            product_id=product_id,
            items=mapping_results,
        )

        return state
