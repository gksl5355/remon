"""
score_impact.py
"""

from __future__ import annotations

import os
import json
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path
import httpx

from openai import OpenAI
from typing import Any, Dict, List

from app.ai_pipeline.state import (
    AppState,
    MappingResults,
    StrategyResults,
    ImpactScoreItem,
)
from app.ai_pipeline.prompts.impact_prompt import IMPACT_PROMPT

import logging

logger = logging.getLogger(__name__)

# -----------------------------------------------------
# ENV & OpenAI Client
# -----------------------------------------------------
ROOT_DIR = Path(__file__).resolve().parents[3]
ENV_PATH = ROOT_DIR / ".env"
load_dotenv(dotenv_path=ENV_PATH, override=True)

client_openai = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    http_client=httpx.Client(trust_env=False)
)


# -----------------------------------------------------
# Utility: months_left ê³„ì‚°
# -----------------------------------------------------
def calculate_months_left(effective_date: str, analysis_date: str):
    if not effective_date:
        return None

    try:
        ed = datetime.strptime(effective_date, "%Y-%m-%d").date()
        ad = datetime.strptime(analysis_date, "%Y-%m-%d").date()
        days = (ed - ad).days
        months = round(days / 30, 2)
        return max(months, 0)
    except Exception:
        return None


# -----------------------------------------------------
# LangGraph Node
# -----------------------------------------------------

async def score_impact_node(state: AppState) -> AppState:

    regulation = state.get("regulation", {})
    mapping: MappingResults | None = state.get("mapping")
    strategies_list = state.get("strategies", [])

    # ë§¤í•‘/ì „ëµ ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if not mapping or not strategies_list:
        logger.warning("[Impact] Skip: mapping or strategies missing")
        return state

    logger.info("[Impact] Starting impact scoring...")
    logger.debug("[Impact] Mapping items: %s", mapping.get("items"))
    logger.debug("[Impact] Strategy items: %s", strategies_list)

    # -----------------------------
    # INPUT ì „ì²˜ë¦¬
    # -----------------------------
    regulation_text = (
        regulation.get("text")
        or (mapping.get("items") or [{}])[0].get("regulation_summary")
        or ""
    )

    effective_date = regulation.get("effective_date")
    analysis_date = datetime.today().strftime("%Y-%m-%d")
    months_left = calculate_months_left(effective_date, analysis_date)

    # ì œí’ˆ ë§¤í•‘ JSON êµ¬ì„±
    products_json_list = []
    for item in mapping["items"]:
        products_json_list.append({
            "product_id": item.get("product_id"),
            "feature_name": item.get("feature_name"),
            "current_value": item.get("current_value"),
            "required_value": item.get("required_value"),
            "gap": item.get("gap"),
        })

    # âœ… CoT êµ¬ì¡° ì „ëµ ì²˜ë¦¬
    if strategies_list and isinstance(strategies_list[0], dict):
        # CoT êµ¬ì¡°: recommended_strategyë§Œ ì¶”ì¶œ
        strategy_text = " ".join([s.get("recommended_strategy", "") for s in strategies_list if s.get("recommended_strategy")]).strip()
    else:
        # Legacy êµ¬ì¡°: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
        strategy_text = " ".join(strategies_list).strip()

    # -----------------------------
    # í”„ë¡¬í”„íŠ¸ ìƒì„± + ë¡œê·¸
    # -----------------------------

    # refined prompt ìš°ì„  ì ìš©
    if state.get("refined_score_impact_prompt"):
        prompt = state["refined_score_impact_prompt"]
        logger.info("[Impact] Using REFINED IMPACT PROMPT from validator")
        logger.debug(f"[Impact] Refined prompt content: {prompt[:200]}...")  # ë””ë²„ê¹…ìš©
    else:
        prompt = IMPACT_PROMPT.format(
            regulation_text=regulation_text,
            products_json=json.dumps(products_json_list, ensure_ascii=False, indent=2),
            strategy_text=strategy_text,
            months_left=months_left,
        )

    logger.debug("\n\n[Impact Prompt]\n%s\n", prompt)

    # -----------------------------
    # LLM í˜¸ì¶œ
    # -----------------------------
    try:
        response = client_openai.chat.completions.create(
            model=os.getenv("LLM_MODEL", "gpt-4o-mini"),
            messages=[
                {"role": "system", "content": "Respond ONLY with valid JSON."},
                {"role": "user", "content": prompt},
            ],
            temperature=0,
        )
        raw_llm_output = response.choices[0].message.content
        logger.debug("\n[Impact Raw LLM Output]\n%s\n", raw_llm_output)

        llm_out = json.loads(raw_llm_output)

    except Exception as e:
        logger.error("[Impact] LLM JSON parsing failed: %s", e)
        return state

    # -----------------------------
    # ì ìˆ˜ ë¶„ë¦¬
    # -----------------------------
    reasoning = llm_out.pop("reasoning", "")
    raw_scores = llm_out

    logger.debug("[Impact] Raw score dict: %s", raw_scores)

    # ğŸ”§ LLMì´ dictë¡œ ë°˜í™˜í•œ ê²½ìš° ìˆ«ì ì¶”ì¶œ
    for key, value in list(raw_scores.items()):
        if isinstance(value, dict):
            # ìŠ¤í‚¤ë§ˆ ë°˜í™˜ ê°ì§€ (type/description í•„ë“œ)
            if 'type' in value and 'description' in value:
                logger.error(f"[Impact] {key} is schema, not score! Skipping...")
                raw_scores[key] = 0
            else:
                raw_scores[key] = value.get('score') or value.get('value') or 0
                logger.warning(f"[Impact] {key} was dict, extracted: {raw_scores[key]}")

    # -----------------------------
    # ê°€ì¤‘í•© ê³„ì‚° ë° HITL ê°•ì œ ë ˆë²¨ ì ìš©
    # -----------------------------
    weights = {
        "directness": 0.20,
        "legal_severity": 0.25,
        "scope": 0.20,
        "regulatory_urgency": 0.10,
        "operational_urgency": 0.10,
        "response_cost": 0.20,
    }

    weighted_score = sum(raw_scores.get(k, 0) * w for k, w in weights.items())
    
    # HITL refined promptì—ì„œ ê°•ì œ ë ˆë²¨ ì§€ì •ì´ ìˆëŠ”ì§€ í™•ì¸
    if state.get("refined_score_impact_prompt"):
        refined_prompt = state["refined_score_impact_prompt"]
        
        # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ ìˆœì„œ ë³€ê²½ (HIGH â†’ MEDIUM â†’ LOW)
        if "Force impact_level to 'High'" in refined_prompt or "FORCE IMPACT_LEVEL TO 'HIGH'" in refined_prompt.upper():
            impact_level = "High"
            weighted_score = 4.5
            logger.info("[Impact] âœ… HITL override: Force High level (4.5)")
        elif "Force impact_level to 'Medium'" in refined_prompt or "FORCE IMPACT_LEVEL TO 'MEDIUM'" in refined_prompt.upper():
            impact_level = "Medium"
            weighted_score = 3.0
            logger.info("[Impact] âœ… HITL override: Force Medium level (3.0)")
        elif "Force impact_level to 'Low'" in refined_prompt or "FORCE IMPACT_LEVEL TO 'LOW'" in refined_prompt.upper():
            impact_level = "Low"
            weighted_score = 2.0
            logger.info("[Impact] âœ… HITL override: Force Low level (2.0)")
        else:
            # ê¸°ë³¸ ë¡œì§
            impact_level = (
                "High" if weighted_score >= 4 else
                "Medium" if weighted_score >= 2.5 else
                "Low"
            )
            logger.warning(f"[Impact] âš ï¸ HITL prompt ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ ë¡œì§ ì‚¬ìš©: {refined_prompt[:100]}...")
    else:
        # ê¸°ë³¸ ë¡œì§
        impact_level = (
            "High" if weighted_score >= 4 else
            "Medium" if weighted_score >= 2.5 else
            "Low"
        )

    # -----------------------------
    # ê²°ê³¼ ìƒì„± (HITL ê·¼ê±° ì²˜ë¦¬)
    # -----------------------------
    # HITLì—ì„œ ê·¼ê±°ë¥¼ 'Human in the loop'ìœ¼ë¡œ ëŒ€ì²´
    if state.get("refined_score_impact_prompt"):
        if "reasoning to 'Human in the loop'" in state["refined_score_impact_prompt"]:
            reasoning = "Human in the loop"
            logger.info("[Impact] âœ… HITL override: reasoning set to 'Human in the loop'")
    elif isinstance(reasoning, dict):
        # ìŠ¤í‚¤ë§ˆ ë°˜í™˜ ê°ì§€
        logger.error(f"[Impact] reasoning is schema: {reasoning}")
        reasoning = "LLM returned schema instead of reasoning"
    
    impact_item: ImpactScoreItem = {
        "raw_scores": raw_scores,
        "weighted_score": round(weighted_score, 2),
        "impact_level": impact_level,
        "reasoning": reasoning,
    }

    # HITL ì¬ì‹¤í–‰ ì‹œ ê¸°ì¡´ ê²°ê³¼ êµì²´
    state["impact_scores"] = [impact_item]

    logger.info("[Impact] Final Impact Score: %s (Level: %s, Score: %.2f)", 
                impact_item, impact_level, weighted_score)
    
    # refined prompt ì œê±° (ì¬ì‹¤í–‰ ë°©ì§€)
    if state.get("refined_score_impact_prompt"):
        state["refined_score_impact_prompt"] = None
        logger.info("[Impact] âœ… HITL refined prompt ì ìš© ì™„ë£Œ (ì œê±°ë¨)")

    # ğŸ†• ì¤‘ê°„ ê²°ê³¼ë¬¼ ì €ì¥ (HITLìš©)
    regulation_id = None
    regulation = state.get("regulation", {})
    if regulation:
        regulation_id = regulation.get("regulation_id")
    
    if not regulation_id:
        preprocess_results = state.get("preprocess_results", [])
        if preprocess_results:
            regulation_id = preprocess_results[0].get("regulation_id")
    
    if regulation_id and state.get("impact_scores"):
        from app.core.repositories.intermediate_output_repository import IntermediateOutputRepository
        from app.core.database import AsyncSessionLocal
        
        logger.info(f"ğŸ’¾ ì˜í–¥ë„ ì¤‘ê°„ ê²°ê³¼ë¬¼ ì €ì¥ ì‹œì‘: regulation_id={regulation_id}")
        
        async with AsyncSessionLocal() as session:
            intermediate_repo = IntermediateOutputRepository()
            try:
                intermediate_data = {
                    "impact_scores": state["impact_scores"],
                    "raw_scores": impact_item.get("raw_scores"),
                    "weighted_score": impact_item.get("weighted_score"),
                    "impact_level": impact_item.get("impact_level"),
                    "reasoning": impact_item.get("reasoning"),
                }
                await intermediate_repo.save_intermediate(
                    session,
                    regulation_id=regulation_id,
                    node_name="score_impact",
                    data=intermediate_data
                )
                await session.commit()
                logger.info(f"âœ… ì˜í–¥ë„ ì¤‘ê°„ ê²°ê³¼ë¬¼ ì €ì¥ ì™„ë£Œ: regulation_id={regulation_id}")
            except Exception as db_err:
                await session.rollback()
                logger.error(f"âŒ ì˜í–¥ë„ ì¤‘ê°„ ê²°ê³¼ë¬¼ ì €ì¥ ì‹¤íŒ¨: {db_err}")
    else:
        logger.warning(f"âš ï¸ ì˜í–¥ë„ ì¤‘ê°„ ê²°ê³¼ë¬¼ ì €ì¥ ìŠ¤í‚µ: regulation_id={regulation_id}")

    return state
