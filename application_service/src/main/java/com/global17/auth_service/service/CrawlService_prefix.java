package com.global17.auth_service.service;

import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.model.ObjectMetadata;
import com.global17.auth_service.entity.CrawlTarget;
import com.global17.auth_service.repository.CrawlTargetRepository;
import com.global17.auth_service.util.TavilyClient;
import lombok.RequiredArgsConstructor;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.ContentDisposition;
import org.springframework.http.HttpEntity;
import org.springframework.http.HttpHeaders;
import org.springframework.http.HttpMethod;
import org.springframework.http.ResponseEntity;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;

import java.io.ByteArrayInputStream;
import java.net.URI;
import java.net.URL;
import java.net.URLDecoder;
import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.time.LocalDate;
import java.time.ZoneId;
import java.time.format.DateTimeFormatter;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

@Service
@RequiredArgsConstructor
public class CrawlService_prefix {

    private final TavilyClient tavilyClient;
    private final AmazonS3 amazonS3; 
    private final CrawlTargetRepository targetRepository;
    
    private final RestTemplate restTemplate = new RestTemplate();
    private final Random random = new Random();

    @Value("${aws.s3.target-arn}")
    private String bucket;

    @Value("${aws.s3.base-prefix}")
    private String basePrefix;

    @Value("${aws.s3.app-prefix}")
    private String appPrefix;

    // --- ì‹¤í–‰ ë¡œì§ ---

    public void runBatchCrawling() {
        System.out.println("ğŸ”„ [Versioning Mode] S3 ë²„ì €ë‹ ê¸°ë°˜ í¬ë¡¤ë§ ì‹œì‘...");
        List<CrawlTarget> targets = targetRepository.findByEnabledTrue();
        if (targets.isEmpty()) {
            System.out.println("âš ï¸ í™œì„±í™”ëœ íƒ€ê²Ÿì´ ì—†ìŠµë‹ˆë‹¤.");
            return;
        }

        for (CrawlTarget target : targets) {
            System.out.println("ğŸ‘‰ Target: " + target.getCountry());
            for (String keyword : target.getKeywords()) {
                processCrawling(target.getCountry(), target.getCode(), keyword, target.getCategory());
                randomSleep(3000, 5000);
            }
        }
        System.out.println("ğŸ‰ [Batch] ì™„ë£Œ!");
    }

    private void processCrawling(String country, String countryCode, String keyword, String category) {
        System.out.println("   ğŸš€ íƒìƒ‰: " + keyword);
        String query = keyword;
        if ("regulation".equalsIgnoreCase(category)) {
             query += " filetype:pdf";
        }

        List<Map<String, String>> searchResults = tavilyClient.search(query);
        if (searchResults.isEmpty()) {
            System.out.println("      ğŸ’¨ ê²°ê³¼ ì—†ìŒ");
            return;
        }

        for (Map<String, String> result : searchResults) {
            String rawUrl = result.get("url");
            String title = result.get("title"); // ê²€ìƒ‰ ì œëª© (Fallbackìš©)

            randomSleep(2000, 4000);

            try {
                URI safeUri = encodeUrl(rawUrl);
                HttpHeaders requestHeaders = createBrowserHeaders();
                HttpEntity<String> entity = new HttpEntity<>(requestHeaders);

                ResponseEntity<byte[]> response = restTemplate.exchange(
                        safeUri, HttpMethod.GET, entity, byte[].class
                );
                
                byte[] fileContent = response.getBody();
                HttpHeaders responseHeaders = response.getHeaders();

                if (fileContent != null && fileContent.length > 2000) {
                    boolean isPdf = isPdfContent(fileContent);
                    String ext = isPdf ? ".pdf" : ".txt";

                    // [í•µì‹¬ ìˆ˜ì •] ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ (Header -> URL -> Title ìˆœì„œ)
                    String realFileName = extractRealFileName(responseHeaders, rawUrl, title, ext);

                    // S3 ì „ì²´ ê²½ë¡œ ì¡°ë¦½
                    String fullKey = buildFullPath(category, countryCode, realFileName);

                    // [ì¤‘ë³µ ì²´í¬]
                    if (isSameContentExists(fullKey, fileContent)) {
                        System.out.println("      â­ï¸ ë³€ê²½ ì—†ìŒ(Skip): " + realFileName + " [URL: " + rawUrl + "]");
                        continue;
                    }
                    
                    byte[] finalContent = isPdf ? fileContent : cleanHtmlToText(fileContent);
                    String publishDate = resolvePublishDate(result, rawUrl, finalContent, isPdf, responseHeaders);

                    uploadToS3(fullKey, fileContent, isPdf, publishDate, rawUrl);
                    
                    System.out.println("      âœ… S3 ì—…ë°ì´íŠ¸: " + fullKey + " [URL: " + rawUrl + "]");

                } else {
                    System.out.println("      âš ï¸ íŒŒì¼ ì‘ìŒ/ì°¨ë‹¨ -> Skip [URL: " + rawUrl + "]");
                }
            } catch (Exception e) {
                System.err.println("      âŒ ì‹¤íŒ¨: " + rawUrl + " -> " + e.toString());
            }
        }
    }

    // --- [ì‹ ê·œ ë©”ì„œë“œ] ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ ë¡œì§ ---
    private String extractRealFileName(HttpHeaders headers, String fileUrl, String fallbackTitle, String defaultExt) {
        String filename = null;

        // 1. Content-Disposition í—¤ë” í™•ì¸ (ê°€ì¥ ì •í™•)
        try {
            ContentDisposition contentDisposition = headers.getContentDisposition();
            if (contentDisposition != null && contentDisposition.getFilename() != null) {
                filename = contentDisposition.getFilename();
                // ì¸ì½”ë”©ëœ íŒŒì¼ëª…ì´ ìˆì„ ê²½ìš° ë””ì½”ë”© ì‹œë„ (UTF-8 ë“±)
                if (contentDisposition.getFilename() == null && headers.getFirst("Content-Disposition") != null) {
                     String rawHeader = headers.getFirst("Content-Disposition");
                     // ë‹¨ìˆœ ì •ê·œì‹ìœ¼ë¡œ filename="abc.pdf" ì¶”ì¶œ ì‹œë„
                     Pattern p = Pattern.compile("filename=\"?([^;\"]+)\"?");
                     Matcher m = p.matcher(rawHeader);
                     if (m.find()) filename = m.group(1);
                }
            }
        } catch (Exception ignored) {}

        // 2. URL ê²½ë¡œì—ì„œ ì¶”ì¶œ (http://site.com/data/report_2024.pdf -> report_2024.pdf)
        if (filename == null || filename.isEmpty()) {
            try {
                String path = new URL(fileUrl).getPath();
                if (path != null && path.contains("/")) {
                    filename = path.substring(path.lastIndexOf("/") + 1);
                    // URL ë””ì½”ë”© (%20 -> ê³µë°±)
                    filename = URLDecoder.decode(filename, StandardCharsets.UTF_8.name());
                }
            } catch (Exception ignored) {}
        }

        // 3. íŒŒì¼ëª…ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìœ¼ë©´ ì œëª©(Fallback) ì‚¬ìš©
        if (filename == null || filename.trim().length() < 3) {
            filename = cleanFileName(fallbackTitle);
        }

        // 4. ìµœì¢… ì •ì œ (í™•ì¥ì ì²˜ë¦¬ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        filename = sanitizeFileName(filename);

        // í™•ì¥ìê°€ ì—†ìœ¼ë©´ ë¶™ì—¬ì¤Œ
        if (!filename.toLowerCase().endsWith(defaultExt)) {
            filename += defaultExt;
        }

        return filename;
    }

    // íŒŒì¼ëª… íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê¸¸ì´ ì œí•œ
    private String sanitizeFileName(String name) {
        // ìœˆë„ìš°/ë¦¬ëˆ…ìŠ¤ íŒŒì¼ëª… ê¸ˆì§€ ë¬¸ì ì œê±°
        String safeName = name.replaceAll("[\\\\/:*?\"<>|]", "_");
        // ê³µë°±ì„ ì–¸ë”ë°”ë¡œ
        safeName = safeName.trim().replaceAll("\\s+", "_");
        
        // ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¦„ (S3 ì œí•œ ê³ ë ¤)
        if (safeName.length() > 200) {
            String ext = "";
            int dotIndex = safeName.lastIndexOf(".");
            if (dotIndex > 0) {
                ext = safeName.substring(dotIndex);
                safeName = safeName.substring(0, 200) + ext;
            } else {
                safeName = safeName.substring(0, 200);
            }
        }
        return safeName;
    }

    // --- ê²½ë¡œ ì¡°ë¦½ê¸° ---
    private String buildFullPath(String category, String countryCode, String fileName) {
        StringBuilder path = new StringBuilder();
        if (basePrefix != null && !basePrefix.isEmpty()) path.append(basePrefix).append("/");
        if (appPrefix != null && !appPrefix.isEmpty()) path.append(appPrefix).append("/");
        path.append(category).append("/").append(countryCode).append("/").append(fileName);
        return path.toString();
    }

    // --- S3 ê´€ë ¨ í•µì‹¬ ë¡œì§ ---

    private boolean isSameContentExists(String key, byte[] newContent) {
        try {
            if (!amazonS3.doesObjectExist(bucket, key)) return false;
            ObjectMetadata metadata = amazonS3.getObjectMetadata(bucket, key);
            String existingETag = metadata.getETag().replace("\"", "");
            String newMD5 = calculateMD5(newContent);
            return existingETag.equalsIgnoreCase(newMD5);
        } catch (Exception e) { return false; }
    }

    private void uploadToS3(String key, byte[] content, boolean isPdf, String date, String url) {
        ObjectMetadata metadata = new ObjectMetadata();
        metadata.setContentLength(content.length);
        metadata.setContentType(isPdf ? "application/pdf" : "text/plain");
        metadata.addUserMetadata("original-date", date);
        metadata.addUserMetadata("source-url", url);
        amazonS3.putObject(bucket, key, new ByteArrayInputStream(content), metadata);
    }

    private String calculateMD5(byte[] content) {
        try {
            StringBuilder sb = new StringBuilder();
            for (byte b : MessageDigest.getInstance("MD5").digest(content)) {
                sb.append(String.format("%02x", b));
            }
            return sb.toString();
        } catch (Exception e) { throw new RuntimeException(e); }
    }

    // --- ìœ í‹¸ ë©”ì„œë“œ ---
    
    // (ê¸°ì¡´ cleanFileNameì€ sanitizeFileNameìœ¼ë¡œ ëŒ€ì²´ë¨, ì œëª© í´ë°±ìš©ìœ¼ë¡œ ìœ ì§€)
    private String cleanFileName(String title) {
        return sanitizeFileName(title);
    }

    private HttpHeaders createBrowserHeaders() {
        HttpHeaders headers = new HttpHeaders();
        headers.set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36");
        headers.set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8");
        headers.set("Accept-Language", "en-US,en;q=0.9,ko;q=0.8");
        headers.set("Referer", "https://www.google.com/");
        headers.set("Connection", "keep-alive");
        return headers;
    }
    
    private void randomSleep(int min, int max) {
        try { Thread.sleep(random.nextInt(max - min + 1) + min); } catch (Exception e) {}
    }
    
    private URI encodeUrl(String urlStr) throws Exception {
        String decoded = URLDecoder.decode(urlStr, StandardCharsets.UTF_8.name());
        URL url = new URL(decoded);
        return new URI(url.getProtocol(), url.getUserInfo(), url.getHost(), url.getPort(), url.getPath(), url.getQuery(), null);
    }
    
    private boolean isPdfContent(byte[] data) {
        return data.length > 4 && data[0]==0x25 && data[1]==0x50 && data[2]==0x44;
    }

    // ë‚ ì§œ ì¶”ì¶œ ë©”ì„œë“œ
    private String resolvePublishDate(Map<String, String> searchResult, String url, byte[] fileContent, boolean isPdf, HttpHeaders headers) {
        String foundDate = extractDateFromUrl(url);
        if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
        if (searchResult.get("published_date") != null) foundDate = searchResult.get("published_date");
        if (foundDate == null && searchResult.get("date") != null) foundDate = searchResult.get("date");
        if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
        if (!isPdf) {
            try {
                String html = new String(fileContent, StandardCharsets.UTF_8);
                Document doc = Jsoup.parse(html);
                foundDate = extractDateFromJsonLd(doc);
                if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
                foundDate = extractDateFromMetaTags(doc);
                if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
                foundDate = extractDateFromDomElements(doc);
                if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
                foundDate = findDatePatternInText(doc.text().substring(0, Math.min(doc.text().length(), 3000)));
                if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
            } catch (Exception ignored) {}
        }
        if (headers.getLastModified() > 0) {
            try {
                foundDate = java.time.Instant.ofEpochMilli(headers.getLastModified()).atZone(ZoneId.of("UTC")).toLocalDate().format(DateTimeFormatter.ISO_DATE);
                if (foundDate != null) return formatDateToYYYYMMDD(foundDate);
            } catch (Exception ignored) {}
        }
        if (searchResult.get("content") != null) foundDate = findDatePatternInText(searchResult.get("content"));
        return formatDateToYYYYMMDD(foundDate);
    }
    
    // ë‚ ì§œ ì„¸ë¶€ ì¶”ì¶œê¸°
    private String extractDateFromJsonLd(Document doc) {
        Elements scripts = doc.select("script[type=application/ld+json]");
        for (Element script : scripts) {
            String json = script.html();
            Pattern p = Pattern.compile("\"datePublished\"\\s*:\\s*\"([^\"]+)\"");
            Matcher m = p.matcher(json); if (m.find()) return m.group(1);
            Pattern p2 = Pattern.compile("\"dateModified\"\\s*:\\s*\"([^\"]+)\"");
            Matcher m2 = p2.matcher(json); if (m2.find()) return m2.group(1);
        }
        return null;
    }
    private String extractDateFromMetaTags(Document doc) {
        String[] metaNames = { "article:published_time", "article:modified_time", "date", "pubdate", "publish_date", "created_at", "og:updated_time", "regDate" };
        for (String name : metaNames) {
            Element meta = doc.selectFirst("meta[name='" + name + "']");
            if (meta == null) meta = doc.selectFirst("meta[property='" + name + "']");
            if (meta != null && !meta.attr("content").isEmpty()) return meta.attr("content");
        }
        return null;
    }
    private String extractDateFromDomElements(Document doc) {
        String[] selectors = { ".date", ".pubDate", ".published", ".time", "#date", ".reg-date" };
        for (String selector : selectors) {
            Elements elements = doc.select(selector);
            for (Element el : elements) {
                String date = findDatePatternInText(el.text());
                if (date != null) return date;
            }
        }
        return null;
    }
    private String extractDateFromUrl(String url) {
        if (url == null) return null;
        try { url = URLDecoder.decode(url, StandardCharsets.UTF_8.name()); } catch(Exception e) {}
        Pattern pattern = Pattern.compile("(20\\d{2})[-./]?(0[1-9]|1[0-2])[-./]?(0[1-9]|[12]\\d|3[01])");
        Matcher matcher = pattern.matcher(url);
        if (matcher.find()) return matcher.group(0);
        return null;
    }
    private String findDatePatternInText(String text) {
        if (text == null) return null;
        Pattern p1 = Pattern.compile("20\\d{2}[-./](0[1-9]|1[0-2])[-./](0[1-9]|[12]\\d|3[01])");
        Matcher m1 = p1.matcher(text);
        if (m1.find()) return m1.group(0);
        Pattern p2 = Pattern.compile("20\\d{2}ë…„\\s*(0?[1-9]|1[0-2])ì›”\\s*(0?[1-9]|[12]\\d|3[01])ì¼");
        Matcher m2 = p2.matcher(text);
        if (m2.find()) return m2.group(0);
        return null;
    }
    private String formatDateToYYYYMMDD(String rawDate) {
        if (rawDate == null || rawDate.trim().isEmpty()) return LocalDate.now().format(DateTimeFormatter.BASIC_ISO_DATE);
        try {
            String cleanDate = rawDate.replaceAll("[^0-9]", " ").trim();
            String[] parts = cleanDate.split("\\s+");
            if (parts.length >= 3) {
                int y = Integer.parseInt(parts[0]);
                int m = Integer.parseInt(parts[1]);
                int d = Integer.parseInt(parts[2]);
                if (y < 100) y += 2000;
                return String.format("%04d%02d%02d", y, m, d);
            }
            String numbersOnly = rawDate.replaceAll("[^0-9]", "");
            if (numbersOnly.length() >= 8) return numbersOnly.substring(0, 8);
            return LocalDate.now().format(DateTimeFormatter.BASIC_ISO_DATE);
        } catch (Exception e) {
            return LocalDate.now().format(DateTimeFormatter.BASIC_ISO_DATE);
        }
    }
    private byte[] cleanHtmlToText(byte[] b) { try { return Jsoup.parse(new String(b, StandardCharsets.UTF_8)).text().getBytes(StandardCharsets.UTF_8); } catch(Exception e){return b;} }

    // CRUD ë©”ì„œë“œ (TargetController í˜¸í™˜ìš©)
    public List<CrawlTarget> getAllTargets() { return targetRepository.findAll(); }
    public CrawlTarget addTarget(CrawlTarget target) { return targetRepository.save(target); }
    public void deleteTarget(Long id) { targetRepository.deleteById(id); }
    public CrawlTarget updateTarget(Long id, CrawlTarget updatedInfo) {
        CrawlTarget target = targetRepository.findById(id).orElseThrow();
        target.setCountry(updatedInfo.getCountry());
        target.setCode(updatedInfo.getCode());
        target.setCategory(updatedInfo.getCategory());
        target.setEnabled(updatedInfo.isEnabled());
        if (target.getKeywords() != null) target.getKeywords().clear();
        if (updatedInfo.getKeywords() != null) target.getKeywords().addAll(updatedInfo.getKeywords());
        return targetRepository.save(target);
    }
    public void updateTargetStatus(Long id, boolean enabled) {
        CrawlTarget target = targetRepository.findById(id).orElseThrow();
        target.setEnabled(enabled);
        targetRepository.save(target);
    }
}

