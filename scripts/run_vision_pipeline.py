#!/usr/bin/env python
"""
Vision-Centric Preprocessing Pipeline ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Usage:
    uv run python scripts/run_vision_pipeline.py
    uv run python scripts/run_vision_pipeline.py --pdf demo/1.pdf --enable-graph
"""

import asyncio
import logging
import argparse
from pathlib import Path
import sys
from datetime import datetime
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# .env íŒŒì¼ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(project_root / ".env")

from app.ai_pipeline.preprocess.config import PreprocessConfig
from app.ai_pipeline.preprocess.vision_orchestrator import VisionOrchestrator

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)

# ì¶œë ¥ ì €ì¥ ë””ë ‰í† ë¦¬
OUTPUT_DIR = project_root / "data" / "vision_outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def parse_args():
    parser = argparse.ArgumentParser(description="Vision Pipeline ì‹¤í–‰")
    parser.add_argument(
        "--pdf",
        type=str,
        help="ì²˜ë¦¬í•  PDF íŒŒì¼ ê²½ë¡œ (ì§€ì • ì•ˆí•˜ë©´ demo í´ë” ì „ì²´)",
    )
    parser.add_argument(
        "--folder",
        type=str,
        default="app/ai_pipeline/preprocess/demo",
        help="ì²˜ë¦¬í•  PDF í´ë” ê²½ë¡œ (ê¸°ë³¸: demo)",
    )
    parser.add_argument(
        "--enable-graph", action="store_true", help="ì§€ì‹ ê·¸ë˜í”„ ì¶”ì¶œ í™œì„±í™”"
    )
    parser.add_argument(
        "--disable-langsmith", action="store_true", help="LangSmith ì¶”ì  ë¹„í™œì„±í™”"
    )
    parser.add_argument(
        "--save-outputs",
        action="store_true",
        default=True,
        help="LLM ì¶œë ¥ì„ .txtë¡œ ì €ì¥ (ê¸°ë³¸: True)",
    )
    return parser.parse_args()


def save_llm_outputs(result: dict, pdf_name: str, timestamp: str) -> None:
    """LLM ì¶œë ¥ì„ .txt íŒŒì¼ë¡œ ì €ì¥."""
    if result["status"] != "success":
        return

    vision_results = result.get("vision_extraction_result", [])
    
    # íŒŒì¼ëª… ê¸¸ì´ ì œí•œ (80ê¸€ì)
    safe_pdf_name = pdf_name[:80] if len(pdf_name) > 80 else pdf_name

    for page_result in vision_results:
        page_num = page_result["page_num"]
        structure = page_result["structure"]
        markdown_content = structure["markdown_content"]
        model_used = page_result["model_used"]

        # íŒŒì¼ëª…: {pdf_name}_page{num}_{model}_{timestamp}.txt
        filename = f"{safe_pdf_name}_page{page_num:03d}_{model_used}_{timestamp}.txt"
        output_path = OUTPUT_DIR / filename

        # ë©”íƒ€ë°ì´í„° í¬í•¨ ì €ì¥
        content = f"""# Vision LLM Output
# PDF: {pdf_name}
# Page: {page_num}
# Model: {model_used}
# Complexity: {page_result['complexity_score']:.2f}
# Has Table: {page_result['has_table']}
# Tokens Used: {page_result.get('tokens_used', 0)}
# Timestamp: {timestamp}

{markdown_content}
"""

        output_path.write_text(content, encoding="utf-8")

    logger.info(f"ğŸ’¾ LLM ì¶œë ¥ ì €ì¥ ì™„ë£Œ: {OUTPUT_DIR} ({len(vision_results)}ê°œ íŒŒì¼)")


async def process_single_pdf(pdf_path: Path, args, orchestrator) -> dict:
    """ë‹¨ì¼ PDF ì²˜ë¦¬."""
    pdf_name = pdf_path.stem
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    logger.info("=" * 60)
    logger.info(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘: {pdf_path.name}")
    logger.info("=" * 60)

    result = await asyncio.to_thread(orchestrator.process_pdf, str(pdf_path))

    # LLM ì¶œë ¥ ì €ì¥
    if args.save_outputs and result["status"] == "success":
        save_llm_outputs(result, pdf_name, timestamp)

    # ê²°ê³¼ ì¶œë ¥
    if result["status"] == "success":
        vision_results = result.get("vision_extraction_result", [])
        index_summary = result.get("dual_index_summary", {})
        
        gpt4o_count = sum(1 for p in vision_results if p.get("model_used") == "gpt-4o")
        total_tokens = sum(p.get("tokens_used", 0) for p in vision_results)

        logger.info(f"âœ… ì™„ë£Œ: {len(vision_results)}í˜ì´ì§€, {index_summary.get('qdrant_chunks', 0)}ì²­í¬, {total_tokens:,}í† í°")
    else:
        logger.error(f"âŒ ì‹¤íŒ¨: {result.get('error')}")
    
    return result


async def main():
    args = parse_args()

    # LangSmith ì„¤ì •
    if not args.disable_langsmith:
        PreprocessConfig.setup_langsmith()

    # PDF ëª©ë¡ ìˆ˜ì§‘
    pdf_files = []
    
    if args.pdf:
        # ë‹¨ì¼ íŒŒì¼ ì§€ì •
        pdf_path = Path(args.pdf)
        if not pdf_path.is_absolute():
            pdf_path = project_root / pdf_path
        if pdf_path.exists():
            pdf_files = [pdf_path]
        else:
            logger.error(f"âŒ PDF íŒŒì¼ ì—†ìŒ: {pdf_path}")
            return
    else:
        # í´ë” ì „ì²´ ì²˜ë¦¬
        folder_path = Path(args.folder)
        if not folder_path.is_absolute():
            folder_path = project_root / folder_path
        
        if not folder_path.exists():
            logger.error(f"âŒ í´ë” ì—†ìŒ: {folder_path}")
            return
        
        pdf_files = sorted(folder_path.glob("*.pdf"))
        pdf_files = [p for p in pdf_files if not p.name.startswith(".")]
    
    if not pdf_files:
        logger.error("âŒ ì²˜ë¦¬í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return

    logger.info(f"ğŸ“š ì´ {len(pdf_files)}ê°œ PDF íŒŒì¼ ë°œê²¬")
    logger.info(f"ğŸ” ì§€ì‹ ê·¸ë˜í”„: {'í™œì„±í™”' if args.enable_graph else 'ë¹„í™œì„±í™”'}")
    logger.info(f"ğŸ’¾ ì¶œë ¥ ì €ì¥: {'í™œì„±í™”' if args.save_outputs else 'ë¹„í™œì„±í™”'}")

    # Orchestrator ìƒì„±
    orchestrator = VisionOrchestrator()
    if args.enable_graph:
        orchestrator.enable_graph = True

    # ìˆœì°¨ ì²˜ë¦¬
    results = []
    for idx, pdf_path in enumerate(pdf_files, 1):
        logger.info(f"\n[{idx}/{len(pdf_files)}] {pdf_path.name}")
        result = await process_single_pdf(pdf_path, args, orchestrator)
        results.append({"file": pdf_path.name, "status": result["status"]})

    # ì „ì²´ ìš”ì•½
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ")
    logger.info("=" * 60)
    
    success_count = sum(1 for r in results if r["status"] == "success")
    logger.info(f"ì„±ê³µ: {success_count}/{len(results)}")
    
    if success_count < len(results):
        logger.info("\nì‹¤íŒ¨ íŒŒì¼:")
        for r in results:
            if r["status"] != "success":
                logger.info(f"  - {r['file']}")
    
    if args.save_outputs:
        logger.info(f"\nğŸ“ ì¶œë ¥ ìœ„ì¹˜: {OUTPUT_DIR}")


if __name__ == "__main__":
    asyncio.run(main())
