#!/usr/bin/env python3
"""
RAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì½˜ì†”
Qdrantì— ì €ì¥ëœ ë°ì´í„°ë¡œ OpenAI ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from app.vectorstore.vector_client import VectorClient
from app.ai_pipeline.preprocess.embedding_pipeline import EmbeddingPipeline
import os

try:
    from openai import OpenAI

    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("âŒ openai ë¯¸ì„¤ì¹˜. pip install openai í•„ìš”")
    sys.exit(1)


class SimpleRAG:
    """ê°„ë‹¨í•œ RAG ì‹œìŠ¤í…œ"""

    def __init__(self):
        try:
            self.vc = VectorClient()
            print("âœ… Qdrant ë²¡í„°DB ì—°ê²° ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  drant ì—°ê²° ì‹¤íŒ¨: {e}")
            self.vc = None

        try:
            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹œë„
            self.embedder = EmbeddingPipeline(use_sparse=False)
            print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   í•´ê²°ë°©ë²•: uv pip install sentence-transformers FlagEmbedding")
            self.embedder = None

        try:
            self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            if not os.getenv("OPENAI_API_KEY"):
                print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì •")
            else:
                print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None

        print()

    def search(self, query: str, top_k: int = 3):
        """Qdrant ê²€ìƒ‰"""
        if self.embedder is None:
            print("âŒ ì˜¤ë¥˜: ì„ë² ë”© ëª¨ë¸ ë¯¸ë¡œë“œ")
            return {"ids": [], "documents": [], "metadatas": [], "scores": []}

        if self.vc is None:
            print("âŒ ì˜¤ë¥˜: Qdrant ì—°ê²° ì‹¤íŒ¨")
            return {"ids": [], "documents": [], "metadatas": [], "scores": []}

        print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}'")

        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_result = self.embedder.embed_single_text(query)
            query_emb = query_result.get("dense")

            if query_emb is None:
                print("âŒ ì˜¤ë¥˜: ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return {"ids": [], "documents": [], "metadatas": [], "scores": []}

            # Qdrant ê²€ìƒ‰
            results = self.vc.search(query_dense=query_emb, top_k=top_k)

            print(f"âœ… {len(results.get('ids', []))}ê°œ ê²°ê³¼ ë°œê²¬\n")
            return results

        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"ids": [], "documents": [], "metadatas": [], "scores": []}

    def generate_answer(self, query: str, search_results):
        """OpenAIë¡œ ë‹µë³€ ìƒì„±"""
        if self.client is None:
            print("âŒ ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ ë¯¸ì´ˆê¸°í™”")
            return "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        if not search_results.get("ids"):
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ì„œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for idx, (doc, meta, score) in enumerate(
                zip(
                    search_results.get("documents", []),
                    search_results.get("metadatas", []),
                    search_results.get("scores", []),
                ),
                1,
            ):
                context_parts.append(
                    f"[ë¬¸ì„œ {idx}] (ê´€ë ¨ë„: {score:.2f})\n"
                    f"ì¶œì²˜: {meta.get('meta_title', 'N/A')}\n"
                    f"ë‚´ìš©: {doc}\n"
                )

            context = "\n".join(context_parts)

            # OpenAI í˜¸ì¶œ
            print("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n")
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "You are a regulatory documents expert. Answer accurately based on the provided documents, and present numerical or tabular content as well-formatted tables.",
                    },
                    {
                        "role": "user",
                        "content": f"ì§ˆë¬¸: {query}\n\nì°¸ê³  ë¬¸ì„œ:\n{context}\n\nìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.",
                    },
                ],
                temperature=0.3,
                max_tokens=500,
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}"

    def query(self, question: str):
        """ì „ì²´ RAG íŒŒì´í”„ë¼ì¸"""
        print("=" * 70)
        print(f"ì§ˆë¬¸: {question}")
        print("=" * 70 + "\n")

        # 1. ê²€ìƒ‰
        results = self.search(question, top_k=3)

        if not results.get("ids"):
            print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
            return

        # 2. ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
        print("ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ:\n")
        for idx, (doc, meta, score) in enumerate(
            zip(
                results.get("documents", []),
                results.get("metadatas", []),
                results.get("scores", []),
            ),
            1,
        ):
            print(f"[{idx}] {meta.get('meta_title', 'N/A')} (ê´€ë ¨ë„: {score:.2f})")
            print(f"    {doc[:100]}...\n")

        # 3. ë‹µë³€ ìƒì„±
        answer = self.generate_answer(question, results)

        print("=" * 70)
        print("ğŸ’¡ ë‹µë³€:")
        print("=" * 70)
        print(answer)
        print("=" * 70 + "\n")


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    rag = SimpleRAG()

    print("=" * 70)
    print("ğŸ¯ REMON RAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì½˜ì†”")
    print("=" * 70)
    print("ëª…ë ¹ì–´:")
    print("  - ì§ˆë¬¸ ì…ë ¥: ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”")
    print("  - 'exit' ë˜ëŠ” 'quit': ì¢…ë£Œ")
    print("=" * 70 + "\n")

    while True:
        try:
            query = input("\nì§ˆë¬¸> ").strip()

            if not query:
                continue

            if query.lower() in ["exit", "quit", "q"]:
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            rag.query(query)

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}\n")


def test_mode():
    """í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ìƒ˜í”Œ ì§ˆë¬¸)"""
    rag = SimpleRAG()

    test_questions = [
        "ë‹´ë°° ê·œì œì˜ ì£¼ìš” ë‚´ìš©ì€?",
        "FDAì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€?",
        "ë‹ˆì½”í‹´ í•¨ëŸ‰ ì œí•œì€?",
    ]

    print("=" * 70)
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ìƒ˜í”Œ ì§ˆë¬¸ 3ê°œ")
    print("=" * 70 + "\n")

    for question in test_questions:
        rag.query(question)
        input("\n[Enterë¥¼ ëˆŒëŸ¬ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ...]")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="RAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--test", action="store_true", help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ìƒ˜í”Œ ì§ˆë¬¸)")
    args = parser.parse_args()

    if args.test:
        test_mode()
    else:
        interactive_mode()
