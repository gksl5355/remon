# scripts/run_full_pipeline.py
"""
module: run_full_pipeline.py
description: REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (S3 PDF â†’ ìµœì¢… ë¦¬í¬íŠ¸)
author: AI Agent
created: 2025-01-19
updated: 2025-01-21 (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ í†µí•©: traceable + citation_code íŒŒë¼ë¯¸í„°)

ì‹¤í–‰ ë°©ë²•:
    # Legacy ê·œì œ ì „ì²˜ë¦¬ (1íšŒë§Œ)
    python scripts/run_full_pipeline.py --mode legacy

    # New ê·œì œ ì²˜ë¦¬ (ì „ì²´ íŒŒì´í”„ë¼ì¸ + HITL ëŒ€í™”)
    python scripts/run_full_pipeline.py --mode new
    python scripts/run_full_pipeline.py  # ê¸°ë³¸ê°’ = new
"""

import asyncio
import logging
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

from sqlalchemy import text

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from app.ai_pipeline.graph import build_graph
from app.ai_pipeline.state import AppState
from app.core.database import AsyncSessionLocal
from langsmith import traceable

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
Path("logs").mkdir(exist_ok=True)
Path("output").mkdir(exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f"logs/pipeline_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        ),
    ],
)
logger = logging.getLogger(__name__)


def print_pipeline_summary(final_state: AppState):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 80)

    # ë³€ê²½ ê°ì§€
    change_summary = final_state.get("change_summary", {})
    if change_summary:
        logger.info("\nğŸ” ë³€ê²½ ê°ì§€:")
        logger.info(f"  - ìƒíƒœ: {change_summary.get('status')}")
        logger.info(f"  - ë³€ê²½ ê±´ìˆ˜: {change_summary.get('total_changes', 0)}")
        logger.info(f"  - ê³ ì‹ ë¢°ë„: {change_summary.get('high_confidence_changes', 0)}")

        # ë³€ê²½ ìƒì„¸
        change_results = final_state.get("change_detection_results", [])
        if change_results:
            logger.info("\n  ğŸ“ ë³€ê²½ ìƒì„¸ (ìƒìœ„ 5ê°œ):")
            for idx, result in enumerate(change_results[:5], 1):
                if result.get("change_detected"):
                    logger.info(
                        f"    {idx}. [{result.get('section_ref')}] "
                        f"{result.get('change_type')} - {result.get('confidence_level')}"
                    )

    # ë§¤í•‘
    mapping = final_state.get("mapping", {}) or {}
    mapping_items = mapping.get("items", []) or []
    if mapping_items:
        logger.info("\nğŸ”— ì œí’ˆ-ê·œì œ ë§¤í•‘:")
        logger.info(f"  - ë§¤í•‘ í•­ëª©: {len(mapping_items)}ê°œ")
        applies_count = sum(1 for item in mapping_items if item.get("applies"))
        logger.info(f"  - ì ìš© ëŒ€ìƒ: {applies_count}ê°œ")

    # ì „ëµ
    strategies = final_state.get("strategies", []) or []
    if strategies:
        logger.info("\nğŸ’¡ ëŒ€ì‘ ì „ëµ:")
        logger.info(f"  - ì „ëµ ê°œìˆ˜: {len(strategies)}ê°œ")
        for i, strategy in enumerate(strategies[:3], 1):
            logger.info(f"  {i}. {str(strategy)[:80]}...")

    # ì˜í–¥ë„
    impact_scores = final_state.get("impact_scores", []) or []
    if impact_scores:
        impact = impact_scores[0] or {}
        try:
            score = float(impact.get("weighted_score", 0.0))
        except Exception:
            score = 0.0
        logger.info("\nğŸ“Š ì˜í–¥ë„ í‰ê°€:")
        logger.info(f"  - ì˜í–¥ë„: {impact.get('impact_level')}")
        logger.info(f"  - ì ìˆ˜: {score:.2f}")
    else:
        logger.info("\nğŸ“Š ì˜í–¥ë„ í‰ê°€: ì—†ìŒ")

    # ë¦¬í¬íŠ¸
    report = final_state.get("report", {}) or {}
    if report:
        logger.info("\nğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸:")
        logger.info(f"  - ìƒì„± ì‹œê°: {report.get('generated_at')}")
        logger.info(f"  - ì„¹ì…˜ ìˆ˜: {len(report.get('sections', []) or [])}")
        logger.info(f"  - Report ID: {report.get('report_id')}")

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    logger.info("=" * 80)


async def download_pdf_from_s3(s3_key: str, local_path: str) -> str:
    """S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ"""
    import boto3

    logger.info(f"ğŸ“¥ S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {s3_key}")

    s3_client = boto3.client("s3")
    bucket = "arn:aws:s3:ap-northeast-2:881490135253:accesspoint/sk-team-storage"

    Path(local_path).parent.mkdir(parents=True, exist_ok=True)
    s3_client.download_file(bucket, s3_key, local_path)
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
    return local_path


async def run_legacy_preprocessing():
    """Legacy ê·œì œ ì „ì²˜ë¦¬ ë° DB ì €ì¥ (1íšŒë§Œ ì‹¤í–‰)"""

    legacy_s3_key = "skala2/skala-2.4.17/regulation/US/Regulation Data A (1).pdf"
    local_legacy_path = "/tmp/Regulation_Data_A.pdf"

    logger.info("=" * 80)
    logger.info("ğŸ”§ Legacy ê·œì œ ì „ì²˜ë¦¬ ëª¨ë“œ")
    logger.info("=" * 80)

    # Step 1: S3ì—ì„œ Legacy PDF ë‹¤ìš´ë¡œë“œ
    try:
        logger.info("\n[Step 1] S3ì—ì„œ Legacy ê·œì œ PDF ë‹¤ìš´ë¡œë“œ")
        await download_pdf_from_s3(legacy_s3_key, local_legacy_path)
        logger.info(f"   âœ… Legacy: {local_legacy_path}")
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # Step 2: Legacy ì „ì²˜ë¦¬
    logger.info("\n[Step 2] Legacy ê·œì œ ì „ì²˜ë¦¬ (Vision Pipeline)")
    from app.ai_pipeline.preprocess.vision_orchestrator import VisionOrchestrator

    orchestrator = VisionOrchestrator()
    legacy_result = await orchestrator.process_pdf_async(
        local_legacy_path, use_parallel=True, language_code=None
    )

    if legacy_result.get("status") != "success":
        logger.error("âŒ Legacy ì „ì²˜ë¦¬ ì‹¤íŒ¨")
        return

    logger.info(
        f"  âœ… Legacy ì „ì²˜ë¦¬ ì™„ë£Œ: {len(legacy_result.get('vision_extraction_result', []))}í˜ì´ì§€"
    )

    # Step 3: DB ì €ì¥
    logger.info("\n[Step 3] PostgreSQL DB ì €ì¥")
    from app.core.repositories.regulation_repository import RegulationRepository

    regulation_id = None
    async with AsyncSessionLocal() as session:
        repo = RegulationRepository()
        try:
            legacy_reg = await repo.create_from_vision_result(session, legacy_result)
            await session.commit()
            regulation_id = legacy_reg.regulation_id
            logger.info(f"  âœ… Legacy ì €ì¥ ì™„ë£Œ: regulation_id={regulation_id}")
            logger.info(f"  âœ… citation_code: {legacy_reg.citation_code}")
        except Exception as e:
            await session.rollback()
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback

            traceback.print_exc()
            return

    # Step 4: ì„ë² ë”© (Qdrant ì €ì¥)
    logger.info("\n[Step 4] ì„ë² ë”© ë° VectorDB ì €ì¥")
    from app.ai_pipeline.preprocess.semantic_processing import DualIndexer

    chunks = legacy_result.get("chunks", []) or []
    graph_data = legacy_result.get("graph_data", {"nodes": [], "edges": []}) or {
        "nodes": [],
        "edges": [],
    }
    vision_results = legacy_result.get("vision_extraction_result", []) or []

    if chunks:
        indexer = DualIndexer()
        index_summary = indexer.index(
            chunks=chunks,
            graph_data=graph_data,
            source_file=Path(local_legacy_path).name,
            regulation_id=regulation_id,
            vision_results=vision_results,
        )
        logger.info(f"  âœ… ì„ë² ë”© ì™„ë£Œ: {index_summary.get('qdrant_chunks', 0)}ê°œ ì²­í¬")
    else:
        logger.warning("  âš ï¸ ì²­í¬ ì—†ìŒ, ì„ë² ë”© ìŠ¤í‚µ")

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ Legacy ê·œì œ ì „ì²˜ë¦¬ ì™„ë£Œ (ì„ë² ë”© í¬í•¨)!")
    logger.info("=" * 80)


@traceable(name="REMON_Full_Pipeline", run_type="chain")
async def run_full_pipeline(citation_code: str | None = None):
    """
    Args:
        citation_code: ê·œì œ ì‹ë³„ ì½”ë“œ (Noneì´ë©´ ì „ì²˜ë¦¬ì—ì„œ ìë™ ì¶”ì¶œ)

    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (S3 ìë™ ë¡œë“œ + ë‹¤ì¤‘ íŒŒì¼ ì²˜ë¦¬ + HITL ë£¨í”„)

    íë¦„:
        1. S3ì—ì„œ íŒŒì¼ ë¡œë“œ
        2. ê° íŒŒì¼ë³„ë¡œ ë…ë¦½ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë²ˆì—­ê¹Œì§€)
        3. ì „ì²´ ê²°ê³¼ ìˆ˜ì§‘
        4. HITL ë£¨í”„ (ì‚¬ìš©ì í”¼ë“œë°±)
    """

    logger.info("=" * 80)
    logger.info("ğŸš€ REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ì‹œì‘ (ë‹¤ì¤‘ íŒŒì¼ ì§€ì›)")
    logger.info("=" * 80)

    # ------- ê·¸ë˜í”„ ì»´íŒŒì¼ -------
    # 1) ì „ì²´ ìë™ ì‹¤í–‰ìš© (preprocessë¶€í„°)
    app_full = build_graph(start_node="preprocess")

    # 2) HITL ì¬ì‹¤í–‰ìš© (hitlë¶€í„°) âœ…
    app_hitl = build_graph(start_node="hitl")

    # Step 1: Legacy regulation_id DB ì¡°íšŒ (citation_code ê¸°ë°˜) - ì„ íƒ
    logger.info("\n[Step 1] Legacy regulation_id DB ì¡°íšŒ")
    from app.core.repositories.regulation_repository import RegulationRepository

    legacy_regulation_id = None
    new_regulation_id = None

    if citation_code:
        async with AsyncSessionLocal() as session:
            repo = RegulationRepository()
            try:
                legacy_reg = await repo.find_by_citation_code(
                    session,
                    citation_code=citation_code,
                )
                if legacy_reg:
                    legacy_regulation_id = legacy_reg.regulation_id
                    logger.info(
                        f"  âœ… Legacy ë°œê²¬: regulation_id={legacy_regulation_id}"
                    )
                else:
                    logger.info("  â„¹ï¸ Legacy ì—†ìŒ (ì‹ ê·œ ê·œì œë¡œ ì²˜ë¦¬)")
            except Exception as e:
                logger.warning(f"  âš ï¸ Legacy ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # Step 2: ìµœì‹ /ì´ì „ ê·œì œ ID ê²°ì • (DB ê¸°ì¤€)
    logger.info("\n[Step 2] ê·œì œ ID ê²°ì • (citation_code ê¸°ë°˜)")
    if citation_code:
        async with AsyncSessionLocal() as session:
            repo = RegulationRepository()
            try:
                latest, previous = await repo.find_latest_and_previous_by_citation(
                    session, citation_code
                )
                if latest:
                    new_regulation_id = latest.regulation_id
                    logger.info(f"  âœ… ìµœì‹  ê·œì œ: regulation_id={new_regulation_id}")
                if previous:
                    legacy_regulation_id = previous.regulation_id
                    logger.info(
                        f"  âœ… ì´ì „(legacy): regulation_id={legacy_regulation_id}"
                    )
                elif not legacy_regulation_id:
                    logger.info("  â„¹ï¸ ì´ì „ ë²„ì „ ì—†ìŒ")
            except Exception as e:
                logger.warning(f"  âš ï¸ ê·œì œ ID ê²°ì • ì‹¤íŒ¨: {e}")
    else:
        logger.info("  â„¹ï¸ citation_code ë¯¸ì§€ì • â†’ ì „ì²˜ë¦¬/ë³€ê²½ê°ì§€ ë‹¨ê³„ì—ì„œ ìë™ ì¶”ì¶œ")

    # Step 3: S3ì—ì„œ íŒŒì¼ ë¡œë“œ
    logger.info("\n[Step 3] S3ì—ì„œ íŒŒì¼ ë¡œë“œ")
    from app.ai_pipeline.preprocess.s3_loader import load_today_regulations
    
    pdf_paths = load_today_regulations(date=None)
    
    if not pdf_paths:
        logger.error("âŒ S3ì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    logger.info(f"  âœ… {len(pdf_paths)}ê°œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    for i, path in enumerate(pdf_paths, 1):
        logger.info(f"    {i}. {path}")
    
    # Step 4: ë‹¤ì¤‘ íŒŒì¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    logger.info("\n[Step 4] ë‹¤ì¤‘ íŒŒì¼ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê° íŒŒì¼ë³„ ë…ë¦½ ì²˜ë¦¬)")
    from app.services.ai_service import AIService
    
    service = AIService()
    result = await service.run_multi_file_pipeline(
        pdf_paths=pdf_paths,
        vision_config=None
    )
    
    logger.info("\n[Step 5] ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    logger.info(f"  ğŸ“Š ì „ì²´: {result['total']}ê°œ")
    logger.info(f"  âœ… ì„±ê³µ: {result['succeeded']}ê°œ")
    logger.info(f"  âŒ ì‹¤íŒ¨: {result['failed']}ê°œ")
    
    reports = result.get('reports', [])
    for i, report in enumerate(reports, 1):
        if report.get('report_id'):
            logger.info(f"  ğŸ“„ ë³´ê³ ì„œ {i}: report_id={report['report_id']}")
        else:
            logger.warning(f"  âš ï¸ ë³´ê³ ì„œ {i}: ìƒì„± ì‹¤íŒ¨")

    # ------------------------------------------------------------------
    # Step 6: HITL ì¸í„°ë™í‹°ë¸Œ ë£¨í”„ (ì²« ë²ˆì§¸ ë³´ê³ ì„œ ê¸°ì¤€)
    # ------------------------------------------------------------------
    if not reports or not reports[0].get('report_id'):
        logger.warning("âš ï¸ ë³´ê³ ì„œê°€ ì—†ì–´ HITLì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return result
    
    first_report = reports[0]
    regulation_id = first_report.get('regulation_id')
    
    if not regulation_id:
        logger.warning("âš ï¸ regulation_idê°€ ì—†ì–´ HITLì„ ê±´ë„ˆëœë‹ˆë‹¤")
        return result
    
    logger.info("\n[Step 6] HITL í”¼ë“œë°± ë£¨í”„ ì‹œì‘ (ì²« ë²ˆì§¸ ë³´ê³ ì„œ ê¸°ì¤€)")
    logger.info(f"  ğŸ“„ ëŒ€ìƒ ë³´ê³ ì„œ: report_id={first_report.get('report_id')}")

    async with AsyncSessionLocal() as session:
        while True:
            print("\n" + "-" * 80)
            print("ğŸ’¬ ê²°ê³¼ì— ëŒ€í•œ HITL í”¼ë“œë°±ì„ ì…ë ¥í•˜ì„¸ìš”.")
            print("   - ì˜ˆ) 'ë³€ê²½ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬í•´ì¤˜', 'ë§¤í•‘ ë‹¤ì‹œ í•´ì¤˜', 'ì „ëµ ì¢€ ë” ë³´ìˆ˜ì ìœ¼ë¡œ'")
            print("   - ì•„ë¬´ê²ƒë„ ì…ë ¥í•˜ì§€ ì•Šê³  ì—”í„° â†’ HITL ì¢…ë£Œ")
            print("   - 'exit' / 'quit' / 'ì™„ë£Œ' ì…ë ¥ â†’ HITL ì¢…ë£Œ")
            print("-" * 80)

            try:
                feedback = input("HITL> ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\nHITL ì…ë ¥ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break

            if not feedback or feedback.lower() in {"exit", "quit", "ì™„ë£Œ"}:
                logger.info("HITL ë£¨í”„ ì¢…ë£Œ")
                break

            logger.info(f"[HITL] í”¼ë“œë°±: '{feedback}'")
            
            try:
                hitl_result = await service.run_pipeline_with_hitl(
                    db=session,
                    regulation_id=regulation_id,
                    user_message=feedback,
                    target_node="map_products"
                )
                logger.info(f"âœ… HITL ì¬ì‹¤í–‰ ì™„ë£Œ: {hitl_result}")
            except Exception as e:
                logger.error(f"âŒ HITL ì¬ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
                break

    return result


async def main():
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="REMON AI Pipeline ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--mode",
        choices=["legacy", "new"],
        default="new",
        help="ì‹¤í–‰ ëª¨ë“œ: legacy (Legacy ì „ì²˜ë¦¬ë§Œ), new (ì „ì²´ íŒŒì´í”„ë¼ì¸)",
    )
    parser.add_argument(
        "--citation-code",
        default=None,
        help="(ì„ íƒ) ê·œì œ ì‹ë³„ìš© citation_code (ë¯¸ì§€ì • ì‹œ ì „ì²˜ë¦¬ì—ì„œ ìë™ ì¶”ì¶œ)",
    )
    args = parser.parse_args()

    if args.mode == "legacy":
        await run_legacy_preprocessing()
    else:
        await run_full_pipeline(citation_code=args.citation_code)


if __name__ == "__main__":
    asyncio.run(main())
