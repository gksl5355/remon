"""
module: run_full_pipeline.py
description: REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (S3 PDF â†’ ìµœì¢… ë¦¬í¬íŠ¸)
author: AI Agent
created: 2025-01-19
updated: 2025-01-20 15:30 (LangSmith íŠ¸ë ˆì´ì‹± ì¶”ê°€)

ì‹¤í–‰ ë°©ë²•:
    # Legacy ê·œì œ ì „ì²˜ë¦¬ (1íšŒë§Œ)
    python scripts/run_full_pipeline.py --mode legacy

    # New ê·œì œ ì²˜ë¦¬ (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    python scripts/run_full_pipeline.py --mode new
    python scripts/run_full_pipeline.py  # ê¸°ë³¸ê°’ = new
"""

import asyncio
import logging
import sys
import argparse
import copy
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
from sqlalchemy import text

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from app.ai_pipeline.graph import build_graph
from app.ai_pipeline.preprocess import preprocess_node
from app.ai_pipeline.state import AppState
from app.core.database import AsyncSessionLocal
<<<<<<< HEAD
from langsmith import traceable
=======
from app.core.repositories.product_repository import ProductRepository
>>>>>>> 1e0417fe55574192e20f4d78f81a95f57b1dc6ad

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
Path("logs").mkdir(exist_ok=True)
Path("output").mkdir(exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f'logs/pipeline_run_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        ),
    ],
)
logger = logging.getLogger(__name__)


def extract_metadata(
    vision_result: Dict[str, Any], regulation_id: int
) -> Dict[str, Any]:
    """Vision ê²°ê³¼ì—ì„œ regulation ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    pages = vision_result.get("vision_extraction_result", [])
    if not pages:
        return {
            "country": "US",
            "title": "Unknown Regulation",
            "effective_date": None,
            "regulation_id": regulation_id,
        }

    first_page = pages[0]
    metadata = first_page.get("structure", {}).get("metadata", {})

    return {
        "country": metadata.get("jurisdiction_code", "US"),
        "title": metadata.get("title", "Unknown Regulation"),
        "effective_date": metadata.get("effective_date"),
        "citation_code": metadata.get("citation_code"),
        "authority": metadata.get("authority"),
        "regulation_id": regulation_id,
    }


def print_pipeline_summary(final_state: AppState):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 80)

    # ë³€ê²½ ê°ì§€
    change_summary = final_state.get("change_summary", {})
    if change_summary:
        logger.info(f"\nğŸ” ë³€ê²½ ê°ì§€:")
        logger.info(f"  - ìƒíƒœ: {change_summary.get('status')}")
        logger.info(f"  - ë³€ê²½ ê±´ìˆ˜: {change_summary.get('total_changes', 0)}")
        logger.info(f"  - ê³ ì‹ ë¢°ë„: {change_summary.get('high_confidence_changes', 0)}")

        # ë³€ê²½ ìƒì„¸
        change_results = final_state.get("change_detection_results", [])
        if change_results:
            logger.info(f"\n  ğŸ“ ë³€ê²½ ìƒì„¸ (ìƒìœ„ 5ê°œ):")
            for idx, result in enumerate(change_results[:5], 1):
                if result.get("change_detected"):
                    logger.info(
                        f"    {idx}. [{result.get('section_ref')}] "
                        f"{result.get('change_type')} - {result.get('confidence_level')}"
                    )

    # ë§¤í•‘
    mapping = final_state.get("mapping", {})
    mapping_items = mapping.get("items", [])
    if mapping_items:
        logger.info(f"\nğŸ”— ì œí’ˆ-ê·œì œ ë§¤í•‘:")
        logger.info(f"  - ë§¤í•‘ í•­ëª©: {len(mapping_items)}ê°œ")
        applies_count = sum(1 for item in mapping_items if item.get("applies"))
        logger.info(f"  - ì ìš© ëŒ€ìƒ: {applies_count}ê°œ")

    # ì „ëµ
    strategies = final_state.get("strategies", [])
    if strategies:
        logger.info(f"\nğŸ’¡ ëŒ€ì‘ ì „ëµ:")
        logger.info(f"  - ì „ëµ ê°œìˆ˜: {len(strategies)}ê°œ")
        for i, strategy in enumerate(strategies[:3], 1):
            logger.info(f"  {i}. {strategy[:80]}...")

    # ì˜í–¥ë„
    impact_scores = final_state.get("impact_scores", [])
    if impact_scores:
        impact = impact_scores[0]
        logger.info(f"\nğŸ“Š ì˜í–¥ë„ í‰ê°€:")
        logger.info(f"  - ì˜í–¥ë„: {impact.get('impact_level')}")
        logger.info(f"  - ì ìˆ˜: {impact.get('weighted_score'):.2f}")

    # ë¦¬í¬íŠ¸
    report = final_state.get("report", {})
    if report:
        logger.info(f"\nğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸:")
        logger.info(f"  - ìƒì„± ì‹œê°: {report.get('generated_at')}")
        logger.info(f"  - ì„¹ì…˜ ìˆ˜: {len(report.get('sections', []))}")
        logger.info(f"  - Report ID: {report.get('report_id')}")

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    logger.info("=" * 80)


async def download_pdf_from_s3(s3_key: str, local_path: str) -> str:
    """S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ"""
    import boto3

    logger.info(f"ğŸ“¥ S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {s3_key}")

    s3_client = boto3.client("s3")
    bucket = "arn:aws:s3:ap-northeast-2:881490135253:accesspoint/sk-team-storage"

    Path(local_path).parent.mkdir(parents=True, exist_ok=True)
    s3_client.download_file(bucket, s3_key, local_path)
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
    return local_path


async def run_legacy_preprocessing():
    """Legacy ê·œì œ ì „ì²˜ë¦¬ ë° DB ì €ì¥ (1íšŒë§Œ ì‹¤í–‰)"""

    # í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© ì„¤ì •
    legacy_s3_key = "skala2/skala-2.4.17/regulation/US/Regulation Data A (1).pdf"
    local_legacy_path = "/tmp/Regulation_Data_A.pdf"

    logger.info("=" * 80)
    logger.info("ğŸ”§ Legacy ê·œì œ ì „ì²˜ë¦¬ ëª¨ë“œ")
    logger.info("=" * 80)

    # Step 1: S3ì—ì„œ Legacy PDF ë‹¤ìš´ë¡œë“œ
    try:
        logger.info("\n[Step 1] S3ì—ì„œ Legacy ê·œì œ PDF ë‹¤ìš´ë¡œë“œ")
        await download_pdf_from_s3(legacy_s3_key, local_legacy_path)
        logger.info(f"   âœ… Legacy: {local_legacy_path}")
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # Step 2: Legacy ì „ì²˜ë¦¬
    logger.info("\n[Step 2] Legacy ê·œì œ ì „ì²˜ë¦¬ (Vision Pipeline)")
    from app.ai_pipeline.preprocess.vision_orchestrator import VisionOrchestrator

    orchestrator = VisionOrchestrator()
    legacy_result = await orchestrator.process_pdf_async(
        local_legacy_path, use_parallel=True, language_code=None
    )

    if legacy_result["status"] != "success":
        logger.error("âŒ Legacy ì „ì²˜ë¦¬ ì‹¤íŒ¨")
        return

    logger.info(
        f"  âœ… Legacy ì „ì²˜ë¦¬ ì™„ë£Œ: {len(legacy_result['vision_extraction_result'])}í˜ì´ì§€"
    )

    # Step 3: DB ì €ì¥
    logger.info("\n[Step 3] PostgreSQL DB ì €ì¥")
    from app.core.repositories.regulation_repository import RegulationRepository

    async with AsyncSessionLocal() as session:
        repo = RegulationRepository()
        try:
            legacy_reg = await repo.create_from_vision_result(session, legacy_result)
            await session.commit()
            logger.info(
                f"  âœ… Legacy ì €ì¥ ì™„ë£Œ: regulation_id={legacy_reg.regulation_id}"
            )
            logger.info(f"  âœ… citation_code: {legacy_reg.citation_code}")
        except Exception as e:
            await session.rollback()
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback

            traceback.print_exc()
            return

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ Legacy ê·œì œ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info("=" * 80)


<<<<<<< HEAD
@traceable(name="REMON_Full_Pipeline", run_type="chain")
async def run_full_pipeline():
=======
async def run_full_pipeline(citation_code: str):
>>>>>>> 1e0417fe55574192e20f4d78f81a95f57b1dc6ad
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (LangGraph ë°©ì‹)"""

    # í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© ì„¤ì •
    new_s3_key = "skala2/skala-2.4.17/regulation/US/Regulation Data B (1).pdf"
    local_new_path = "/tmp/Regulation_Data_B.pdf"
    legacy_citation_code = citation_code  # Legacy ê·œì œ ì‹ë³„ìš© ë™ì¼ citation ì‚¬ìš©

    logger.info("=" * 80)
    logger.info("ğŸš€ REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ì‹œì‘")
    logger.info("=" * 80)

    # Step 1: S3ì—ì„œ New ê·œì œ PDF ë‹¤ìš´ë¡œë“œ
    try:
        logger.info("\n[Step 1] S3ì—ì„œ New ê·œì œ PDF ë‹¤ìš´ë¡œë“œ")
        await download_pdf_from_s3(new_s3_key, local_new_path)
        logger.info(f"   âœ… New: {local_new_path}")
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # Step 2: LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (DB ì „ì²´ ì œí’ˆ ìë™ ì²˜ë¦¬)
    logger.info("\n[Step 2] LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (DB ì „ì²´ ì œí’ˆ ìë™ ì²˜ë¦¬)")
    logger.info("  â„¹ï¸ Legacy ê²€ìƒ‰ì€ change_detection_nodeì—ì„œ ìë™ ìˆ˜í–‰ë©ë‹ˆë‹¤")
    logger.info("  â„¹ï¸ ì œí’ˆ ë§¤í•‘ì€ map_products_nodeì—ì„œ DB ì „ì²´ ì œí’ˆì„ ìë™ ì¡°íšŒí•©ë‹ˆë‹¤")

    app = build_graph()

    initial_state: AppState = {
        "preprocess_request": {
            "pdf_paths": [local_new_path],
            "use_vision_pipeline": True,
            "enable_change_detection": True,
        },
        "change_context": {},  # LegacyëŠ” change_detection_nodeê°€ ìë™ ê²€ìƒ‰
        "mapping_filters": {},  # ë¹ˆ ë”•ì…”ë„ˆë¦¬: map_products_nodeê°€ DBì—ì„œ ìë™ ì¡°íšŒ
        "validation_retry_count": 0,
    }
    # Step 2: Legacy regulation_id DB ì¡°íšŒ
    logger.info("\n[Step 2] Legacy regulation_id DB ì¡°íšŒ")
    from app.core.repositories.regulation_repository import RegulationRepository
    
    legacy_regulation_id = None
    async with AsyncSessionLocal() as session:
        repo = RegulationRepository()
        # Step 2: Legacy regulation_id DB ì¡°íšŒ
        try:
            legacy_reg = await repo.find_by_citation_code(
                session,
                citation_code=legacy_citation_code,
            )
            if legacy_reg:
                legacy_regulation_id = legacy_reg.regulation_id
                logger.info(f"  âœ… Legacy ë°œê²¬: regulation_id={legacy_regulation_id}")
            else:
                logger.info("  â„¹ï¸ Legacy ì—†ìŒ (ì‹ ê·œ ê·œì œë¡œ ì²˜ë¦¬)")
        except Exception as e:
            logger.warning(f"  âš ï¸ Legacy ì¡°íšŒ ì‹¤íŒ¨: {e}")

        # Step 3: ìµœì‹ /ì´ì „ ê·œì œ ID ê²°ì • (DB ê¸°ì¤€)
        logger.info("\n[Step 3] ê·œì œ ID ê²°ì • (citation_code ê¸°ë°˜)")
        new_regulation_id = None
        try:
            latest, previous = await repo.find_latest_and_previous_by_citation(
                session, citation_code
            )
            if latest:
                new_regulation_id = latest.regulation_id
                logger.info(f"  âœ… ìµœì‹  ê·œì œ: regulation_id={new_regulation_id}")
            if previous:
                legacy_regulation_id = previous.regulation_id
                logger.info(f"  âœ… ì´ì „(legacy): regulation_id={legacy_regulation_id}")
            elif not legacy_regulation_id:
                logger.info("  â„¹ï¸ ì´ì „ ë²„ì „ ì—†ìŒ")
        except Exception as e:
            logger.warning(f"  âš ï¸ ê·œì œ ID ê²°ì • ì‹¤íŒ¨: {e}")

        # Step 4: ì „ì²˜ë¦¬(+ë³€ê²½ ê°ì§€) 1íšŒ ì‹¤í–‰ â†’ ê²°ê³¼ ì¬ì‚¬ìš©í•˜ì—¬ ì œí’ˆë³„ ë§¤í•‘
        logger.info("\n[Step 4] ì „ì²˜ë¦¬/ë³€ê²½ ê°ì§€ 1íšŒ ì‹¤í–‰ â†’ ê²°ê³¼ ì¬ì‚¬ìš©í•˜ì—¬ ì œí’ˆë³„ ë§¤í•‘")

        # 4-1. ì „ì²˜ë¦¬ 1íšŒ (enable_change_detection=True ì´ë©´ ë‚´ë¶€ì—ì„œ ë³€ê²½ ê°ì§€ê¹Œì§€ ìˆ˜í–‰)
        base_state: AppState = {
            "preprocess_request": {
                "pdf_paths": [local_new_path],
                "use_vision_pipeline": True,
                "enable_change_detection": True,
            },
            "change_context": {
                "legacy_regulation_id": legacy_regulation_id,
                "new_regulation_id": new_regulation_id,
            },
            "validation_retry_count": 0,
        }
        base_state = await preprocess_node(base_state)

        # ì œí’ˆ ëª©ë¡ ì¡°íšŒ (ë³„ë„ ì„¸ì…˜ ì‚¬ìš©)
        product_ids = []
        try:
            async with AsyncSessionLocal() as product_session:
                result = await product_session.execute(
                    text("SELECT product_id FROM products ORDER BY product_id")
                )
                product_ids = [row[0] for row in result.fetchall()]
        except Exception as e:
            logger.error(f"ì œí’ˆ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return

        if not product_ids:
            logger.error("ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤. products í…Œì´ë¸”ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        # ì œí’ˆë³„ ë§¤í•‘/ì „ëµ/ë¦¬í¬íŠ¸ë§Œ ì‹¤í–‰í•˜ëŠ” ê·¸ë˜í”„
        app = build_graph(start_node="map_products")

        final_state = None
        for pid in product_ids:
            logger.info(f"â–¶ï¸ ì œí’ˆ {pid}ì— ëŒ€í•´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì „ì²˜ë¦¬ ì¬ì‚¬ìš©)")
            per_product_state: AppState = copy.deepcopy(base_state)
            per_product_state.update(
                {
                    "mapping_filters": {"product_id": pid},
                    "validation_retry_count": 0,
                }
            )

            try:
                final_state = await app.ainvoke(per_product_state, config={"configurable": {}})
                logger.info(f"âœ… ì œí’ˆ {pid} íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ì œí’ˆ {pid} íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
                continue

    if final_state:
        logger.info("\n[Step 5] ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ (ë§ˆì§€ë§‰ ì œí’ˆ ê¸°ì¤€)")
        print_pipeline_summary(final_state)

    return final_state


async def main():
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description="REMON AI Pipeline ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--mode",
        choices=["legacy", "new"],
        default="new",
        help="ì‹¤í–‰ ëª¨ë“œ: legacy (Legacy ì „ì²˜ë¦¬ë§Œ), new (ì „ì²´ íŒŒì´í”„ë¼ì¸)",
    )
    parser.add_argument(
        "--citation-code",
        default="21 CFR Part 1160",
        help="ê·œì œ ì‹ë³„ìš© citation_code (legacy/new ë§¤ì¹­ì— ì‚¬ìš©)"
    )
    args = parser.parse_args()

    if args.mode == "legacy":
        await run_legacy_preprocessing()
    else:
        await run_full_pipeline(citation_code=args.citation_code)


if __name__ == "__main__":
    asyncio.run(main())
