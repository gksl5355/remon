"""
module: run_full_pipeline.py
description: REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (S3 PDF â†’ ìµœì¢… ë¦¬í¬íŠ¸)
author: AI Agent
created: 2025-01-19
updated: 2025-01-20

ì‹¤í–‰ ë°©ë²•:
    # Legacy ê·œì œ ì „ì²˜ë¦¬ (1íšŒë§Œ)
    python scripts/run_full_pipeline.py --mode legacy
    
    # New ê·œì œ ì²˜ë¦¬ (ì „ì²´ íŒŒì´í”„ë¼ì¸)
    python scripts/run_full_pipeline.py --mode new
    python scripts/run_full_pipeline.py  # ê¸°ë³¸ê°’ = new
"""

import asyncio
import logging
import sys
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

from app.ai_pipeline.graph import build_graph
from app.ai_pipeline.state import AppState
from app.core.database import AsyncSessionLocal

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
Path("logs").mkdir(exist_ok=True)
Path("output").mkdir(exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f'logs/pipeline_run_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        ),
    ],
)
logger = logging.getLogger(__name__)


def extract_metadata(vision_result: Dict[str, Any], regulation_id: int) -> Dict[str, Any]:
    """Vision ê²°ê³¼ì—ì„œ regulation ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    pages = vision_result.get("vision_extraction_result", [])
    if not pages:
        return {
            "country": "US",
            "title": "Unknown Regulation",
            "effective_date": None,
            "regulation_id": regulation_id,
        }
    
    first_page = pages[0]
    metadata = first_page.get("structure", {}).get("metadata", {})
    
    return {
        "country": metadata.get("jurisdiction_code", "US"),
        "title": metadata.get("title", "Unknown Regulation"),
        "effective_date": metadata.get("effective_date"),
        "citation_code": metadata.get("citation_code"),
        "authority": metadata.get("authority"),
        "regulation_id": regulation_id,
    }


def print_pipeline_summary(final_state: AppState):
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 80)

    # ë³€ê²½ ê°ì§€
    change_summary = final_state.get("change_summary", {})
    if change_summary:
        logger.info(f"\nğŸ” ë³€ê²½ ê°ì§€:")
        logger.info(f"  - ìƒíƒœ: {change_summary.get('status')}")
        logger.info(f"  - ë³€ê²½ ê±´ìˆ˜: {change_summary.get('total_changes', 0)}")
        logger.info(f"  - ê³ ì‹ ë¢°ë„: {change_summary.get('high_confidence_changes', 0)}")
        
        # ë³€ê²½ ìƒì„¸
        change_results = final_state.get("change_detection_results", [])
        if change_results:
            logger.info(f"\n  ğŸ“ ë³€ê²½ ìƒì„¸ (ìƒìœ„ 5ê°œ):")
            for idx, result in enumerate(change_results[:5], 1):
                if result.get("change_detected"):
                    logger.info(
                        f"    {idx}. [{result.get('section_ref')}] "
                        f"{result.get('change_type')} - {result.get('confidence_level')}"
                    )

    # ë§¤í•‘
    mapping = final_state.get("mapping", {})
    mapping_items = mapping.get("items", [])
    if mapping_items:
        logger.info(f"\nğŸ”— ì œí’ˆ-ê·œì œ ë§¤í•‘:")
        logger.info(f"  - ë§¤í•‘ í•­ëª©: {len(mapping_items)}ê°œ")
        applies_count = sum(1 for item in mapping_items if item.get("applies"))
        logger.info(f"  - ì ìš© ëŒ€ìƒ: {applies_count}ê°œ")

    # ì „ëµ
    strategies = final_state.get("strategies", [])
    if strategies:
        logger.info(f"\nğŸ’¡ ëŒ€ì‘ ì „ëµ:")
        logger.info(f"  - ì „ëµ ê°œìˆ˜: {len(strategies)}ê°œ")
        for i, strategy in enumerate(strategies[:3], 1):
            logger.info(f"  {i}. {strategy[:80]}...")

    # ì˜í–¥ë„
    impact_scores = final_state.get("impact_scores", [])
    if impact_scores:
        impact = impact_scores[0]
        logger.info(f"\nğŸ“Š ì˜í–¥ë„ í‰ê°€:")
        logger.info(f"  - ì˜í–¥ë„: {impact.get('impact_level')}")
        logger.info(f"  - ì ìˆ˜: {impact.get('weighted_score'):.2f}")

    # ë¦¬í¬íŠ¸
    report = final_state.get("report", {})
    if report:
        logger.info(f"\nğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸:")
        logger.info(f"  - ìƒì„± ì‹œê°: {report.get('generated_at')}")
        logger.info(f"  - ì„¹ì…˜ ìˆ˜: {len(report.get('sections', []))}")
        logger.info(f"  - Report ID: {report.get('report_id')}")

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
    logger.info("=" * 80)


async def download_pdf_from_s3(s3_key: str, local_path: str) -> str:
    """S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ"""
    import boto3

    logger.info(f"ğŸ“¥ S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ì¤‘: {s3_key}")

    s3_client = boto3.client("s3")
    bucket = "arn:aws:s3:ap-northeast-2:881490135253:accesspoint/sk-team-storage"

    Path(local_path).parent.mkdir(parents=True, exist_ok=True)
    s3_client.download_file(bucket, s3_key, local_path)
    logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
    return local_path


async def run_legacy_preprocessing():
    """Legacy ê·œì œ ì „ì²˜ë¦¬ ë° DB ì €ì¥ (1íšŒë§Œ ì‹¤í–‰)"""
    
    # í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© ì„¤ì •
    legacy_s3_key = "skala2/skala-2.4.17/regulation/US/Regulation Data A (1).pdf"
    local_legacy_path = "/tmp/Regulation_Data_A.pdf"
    
    logger.info("=" * 80)
    logger.info("ğŸ”§ Legacy ê·œì œ ì „ì²˜ë¦¬ ëª¨ë“œ")
    logger.info("=" * 80)
    
    # Step 1: S3ì—ì„œ Legacy PDF ë‹¤ìš´ë¡œë“œ
    try:
        logger.info("\n[Step 1] S3ì—ì„œ Legacy ê·œì œ PDF ë‹¤ìš´ë¡œë“œ")
        await download_pdf_from_s3(legacy_s3_key, local_legacy_path)
        logger.info(f"   âœ… Legacy: {local_legacy_path}")
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # Step 2: Legacy ì „ì²˜ë¦¬
    logger.info("\n[Step 2] Legacy ê·œì œ ì „ì²˜ë¦¬ (Vision Pipeline)")
    from app.ai_pipeline.preprocess.vision_orchestrator import VisionOrchestrator
    
    orchestrator = VisionOrchestrator()
    legacy_result = await orchestrator.process_pdf_async(
        local_legacy_path, use_parallel=True, language_code=None
    )
    
    if legacy_result["status"] != "success":
        logger.error("âŒ Legacy ì „ì²˜ë¦¬ ì‹¤íŒ¨")
        return
    
    logger.info(f"  âœ… Legacy ì „ì²˜ë¦¬ ì™„ë£Œ: {len(legacy_result['vision_extraction_result'])}í˜ì´ì§€")
    
    # Step 3: DB ì €ì¥
    logger.info("\n[Step 3] PostgreSQL DB ì €ì¥")
    from app.core.repositories.regulation_repository import RegulationRepository
    
    async with AsyncSessionLocal() as session:
        repo = RegulationRepository()
        try:
            legacy_reg = await repo.create_from_vision_result(session, legacy_result)
            await session.commit()
            logger.info(f"  âœ… Legacy ì €ì¥ ì™„ë£Œ: regulation_id={legacy_reg.regulation_id}")
            logger.info(f"  âœ… citation_code: {legacy_reg.citation_code}")
        except Exception as e:
            await session.rollback()
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ‰ Legacy ê·œì œ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info("=" * 80)


async def run_full_pipeline():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (LangGraph ë°©ì‹)"""

    # í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© ì„¤ì •
    new_s3_key = "skala2/skala-2.4.17/regulation/US/Regulation Data B (1).pdf"
    local_new_path = "/tmp/Regulation_Data_B.pdf"
    legacy_citation_code = "FDA-21CFR-1114"  # Legacy ê·œì œ ì‹ë³„ìš©
    product_id = 1  # í…ŒìŠ¤íŠ¸ìš© ì œí’ˆ ID

    logger.info("=" * 80)
    logger.info("ğŸš€ REMON AI Pipeline ì „ì²´ ì‹¤í–‰ ì‹œì‘")
    logger.info("=" * 80)

    # Step 1: S3ì—ì„œ New ê·œì œ PDF ë‹¤ìš´ë¡œë“œ
    try:
        logger.info("\n[Step 1] S3ì—ì„œ New ê·œì œ PDF ë‹¤ìš´ë¡œë“œ")
        await download_pdf_from_s3(new_s3_key, local_new_path)
        logger.info(f"   âœ… New: {local_new_path}")
    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # Step 2: Legacy regulation_id DB ì¡°íšŒ
    logger.info("\n[Step 2] Legacy regulation_id DB ì¡°íšŒ")
    from app.core.repositories.regulation_repository import RegulationRepository
    
    legacy_regulation_id = None
    async with AsyncSessionLocal() as session:
        repo = RegulationRepository()
        try:
            # citation_codeë¡œ Legacy ê²€ìƒ‰
            legacy_reg = await repo.find_by_citation_code(
                session, 
                citation_code=legacy_citation_code
            )
            if legacy_reg:
                legacy_regulation_id = legacy_reg.regulation_id
                logger.info(f"  âœ… Legacy ë°œê²¬: regulation_id={legacy_regulation_id}")
            else:
                logger.info(f"  â„¹ï¸ Legacy ì—†ìŒ (ì‹ ê·œ ê·œì œë¡œ ì²˜ë¦¬)")
        except Exception as e:
            logger.warning(f"  âš ï¸ Legacy ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # Step 3: LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (preprocessë¶€í„°)
    logger.info("\n[Step 3] LangGraph íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (preprocessë¶€í„°)")
    
    app = build_graph()
    
    initial_state: AppState = {
        "preprocess_request": {
            "pdf_paths": [local_new_path],
            "use_vision_pipeline": True,
            "enable_change_detection": True,
        },
        "change_context": {
            "legacy_regulation_id": legacy_regulation_id,
        },
        "mapping_filters": {"product_id": product_id},
        "validation_retry_count": 0,
    }

    try:
        final_state = await app.ainvoke(initial_state, config={"configurable": {}})
        logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        return

    # Step 4: ê²°ê³¼ ì¶œë ¥
    logger.info("\n[Step 4] ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
    print_pipeline_summary(final_state)

    return final_state


async def main():
    # ëª…ë ¹í–‰ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(
        description="REMON AI Pipeline ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸"
    )
    parser.add_argument(
        "--mode",
        choices=["legacy", "new"],
        default="new",
        help="ì‹¤í–‰ ëª¨ë“œ: legacy (Legacy ì „ì²˜ë¦¬ë§Œ), new (ì „ì²´ íŒŒì´í”„ë¼ì¸)"
    )
    args = parser.parse_args()
    
    if args.mode == "legacy":
        await run_legacy_preprocessing()
    else:
        await run_full_pipeline()


if __name__ == "__main__":
    asyncio.run(main())
